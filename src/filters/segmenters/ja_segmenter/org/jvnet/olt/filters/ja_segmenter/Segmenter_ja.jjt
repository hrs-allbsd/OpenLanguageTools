
/*
 * Copyright  2005 Sun Microsystems, Inc. 
 * All rights reserved Use is subject to license terms.
 *
 */

options{
    NODE_PACKAGE = "org.jvnet.olt.filters.ja_segmenter";
    LOOKAHEAD=4;
    VISITOR = true;
    FORCE_LA_CHECK = true;
    STATIC = false;
    UNICODE_INPUT=true;
    JAVA_UNICODE_ESCAPE = false;

}

PARSER_BEGIN(Segmenter_ja)

package org.jvnet.olt.filters.ja_segmenter;

/** 

  This sentence segmenter is designed to run on Sun Microsystems Inc. documentation
  - as a result, it's quite biased towards technical material, and has a few things
  builtin to deal with these nicely.

  Right now, it's just a copy of the en segmenter, with changes to the word
  counting algorithm, using the BreakIterator instead of the word() tokens
  that are produced from this parser.

*/

// import java.io.*;


public class Segmenter_en {

  /**
   *  A static method to allow the SCCS version of the file to be read at 
   *  runtime.
   */
  public static final String getVersionInfo()
  {
    return "English Segmenter - version: 1.0";
  }

  protected boolean boolParsed = false;

  /**
   *  The method is called by other classes to parse the
   *  current input stream.
   *  @exception  ParseException
   */
  public void parse() throws ParseException
  {
    //  Call top level rule.
    file();
    boolParsed = true;
  }

  /**
   *  walkParseTree:  This method provides an interface to allow node Visitors
   *  to be passed to the parse tree generated by this parser. 
   *  @param  visitor The visitor to act on all the nodes in the parse tree.
   *  @param  data    An object to be used as an aid to the tree walk.
   *  @exception Exception
   */
  public void walkParseTree(Segmenter_enVisitor visitor, Object data) throws Exception
  {
    if(boolParsed && (visitor != null))
    {
      //  Get root node of the parse tree
      SimpleNode node =(SimpleNode) jjtree.rootNode();
      node.jjtAccept(visitor, data);
    }
    else
    {
      //  Throw an exception
      throw new Exception("Input stream not parsed");
    }
  }
  protected void finalize() throws Throwable
  {
    super.finalize();
  }
}

PARSER_END(Segmenter_en)

TOKEN : { <numberdot: "\n" (" "| "\t" | "\f")* ("1." | "2." | "3." | "4." | "5." | "6." | "7." | "8.") >}
TOKEN : {<SLASHNSPACE: (("\n" | "\r\n") ([" ","\t"])+) >}


// whitespace characters
/* the QUOTE token originally had the ' character - but now, we're treating
   it like whitespace, to deal with the SunTrans1 idea that the text "it's" should
   be treated as two words !!
   */
TOKEN :
{
  <WS: (" " |
	"\t" |
	"\b" |
	"\f" 
	/*	"\n" | 
		"\r"*/
        )+ > 
}

TOKEN : { <APOSTROPHE: ("'") > }

TOKEN : { <FORMATTING: ("\n" | "\r")+ > }

// this is a *very* special case - I'm teaching the segmenter about tags, basically
// it should now ignore anything between <..> : thus, it's now important to send
// all tagged text through the segmenter like this - any plaintext that's supposed
// to have tags should have them converted to &lt;...&gt;

MORE:
{
  "<" : IN_TAG
}


<IN_TAG>
TOKEN :
{
   <#TAG_STRING_LIT: "'" ( ~["'"] )* "'" | "\"" ( ~["\""] )* "\""  >
|  <TAG: ">" > : DEFAULT
}

<IN_TAG>
MORE :
{
  < ~[] >
}


// We never segment inside entities like &this.entity; Actually, what happens
// here is that an entity token can suck up the next tag if necessary - but
// the result it the same,
// in that we never segment within an entity. Entities end with one of 
// " " ";" "\n" "\r" and that's all.

TOKEN :
{
  <entity: ( "&" | "%" ) ( ~["<" , " " , "\t" , "\n", "\r", ";" ] )+ (";")? >
}

TOKEN :
{
  <AMP: "&" >
}



// attempt to deal with email addresses
TOKEN :{
    <EMAIL: ((~[ ";","/",":","&","=","+","$",",","[","]","\t"," ","\b","\f","\n","\r","@","!","?","\"",">","<" ])+
	    "@"
	    (~[ ";","/",":","&","=","+","$",",","[","]","\t"," ","\b","\f","\n","\r","@","!","?","\"",">","<" ])+)
            (~[ ";","/",":","&","=","+","$",",","[","]","\t"," ","\b","\f","\n","\r","@","!","?","\"",".",">","<" ])>
}

// attempt to deal with urls

TOKEN : { <URL: ("http://" | "ftp://" | "https://" | "file://" ) 
	    (~[ ";",",","[","]","{","}","(",")",">","<","\t"," ","\b","\f","\n","\r" ])*
	    (~[ ";",",","[","]","{","}","(",")",">","<","\t"," ","\b","\f","\n","\r","." ])
		    
		    >
}

// Something to detect strings like Thu Sep 12 16:24:41 BST 2002
TOKEN : { <TIME: (["0"-"9"])+":"(((["0"-"9"])+":") | ((["0"-"9"])+))+ >
}

// attempt to catch machine/domain names
// note that ".info" is also a filename extension ! be sure not to add it twice :-)
TOKEN : { <NETDOMAIN: (".com" | ".net" | ".co" | ".gov" | ".mil" |
		       ".edu"| ".org"| ".COM" | 
		       // "New" TLDs from http://www.icann.org/tlds/
		       ".biz" | ".info" | ".aero" |
		       ".coop" | ".museum" | ".name" | ".pro"
  // This list of country TLDs is from http://www.iana.org/cctld/cctld-whois.htm
  // I might trim this down a bit if the sheer number of these slow down
  // the lexer too much.
 ".ac" | ".ad" | ".ae" | ".af" | ".ag" | ".ai" | ".al" | ".am" |
 ".an" | ".ao" | ".aq" | ".ar" | ".as" | ".at" | ".au" | ".aw" |
 ".az" | ".ba" | ".bb" | ".bd" | ".be" | ".bf" | ".bg" | ".bh" |
 ".bi" | ".bj" | ".bm" | ".bn" | ".bo" | ".br" | ".bs" | ".bt" |
 ".bv" | ".bw" | ".by" | ".bz" | ".ca" | ".cc" | ".cd" | ".cf" |
 ".cg" | ".ch" | ".ci" | ".ck" | ".cl" | ".cm" | ".cn" | ".co" |
 ".cr" | ".cu" | ".cv" | ".cx" | ".cy" | ".cz" | ".de" | ".dj" |
 ".dk" | ".dm" | ".do" | ".dz" | ".ec" | ".ee" | ".eg" | ".eh" |
 ".er" | ".es" | ".et" | ".fi" | ".fj" | ".fk" | ".fm" | ".fo" |
 ".fr" | ".ga" | ".gd" | ".ge" | ".gf" | ".gg" | ".gh" | ".gi" |
 ".gl" | ".gm" | ".gn" | ".gp" | ".gq" | ".gr" | ".gs" | ".gt" |
 ".gu" | ".gw" | ".gy" | ".hk" | ".hm" | ".hn" | ".hr" | ".ht" |
 ".hu" | ".id" | ".ie" | ".il" | ".im" | ".in" | ".io" | ".iq" |
 ".ir" | ".is" | ".it" | ".je" | ".jm" | ".jo" | ".jp" | ".ke" |
 ".kg" | ".kh" | ".ki" | ".km" | ".kn" | ".kp" | ".kr" | ".kw" |
 ".ky" | ".kz" | ".la" | ".lb" | ".lc" | ".li" | ".lk" | ".lr" |
 ".ls" | ".lt" | ".lu" | ".lv" | ".ly" | ".ma" | ".mc" | ".md" |
 ".mg" | ".mh" | ".mk" | ".ml" | ".mm" | ".mn" | ".mo" | ".mp" |
 ".mq" | ".mr" | ".ms" | ".mt" | ".mu" | ".mv" | ".mw" | ".mx" |
 ".my" | ".mz" | ".na" | ".nc" | ".ne" | ".nf" | ".ng" | ".ni" |
 ".nl" | ".no" | ".np" | ".nr" | ".nu" | ".nz" | ".om" | ".pa" |
 ".pe" | ".pf" | ".pg" | ".ph" | ".pk" | ".pl" | ".pm" | ".pn" |
 ".pr" | ".ps" | ".pt" | ".pw" | ".py" | ".qa" | ".re" | ".ro" |
 ".ru" | ".rw" | ".sa" | ".sb" | ".sc" | ".sd" | ".se" | ".sg" |
 ".sh" | ".si" | ".sj" | ".sk" | ".sl" | ".sm" | ".sn" | ".so" |
 ".sr" | ".st" | ".sv" | ".sy" | ".sz" | ".tc" | ".td" | ".tf" |
 ".tg" | ".th" | ".tj" | ".tk" | ".tm" | ".tn" | ".to" | ".tp" |
 ".tr" | ".tt" | ".tv" | ".tw" | ".tz" | ".ua" | ".ug" | ".uk" |
 ".um" | ".us" | ".uy" | ".uz" | ".va" | ".vc" | ".ve" | ".vg" |
 ".vi" | ".vn" | ".vu" | ".wf" | ".ws" | ".ye" | ".yt" | ".yu"

		       ) >}


// Attempt to catch regularly occuring filename extensions
// - I'm adding brackets here, since these extensions are often
// in brackets like "the portable network graphics format (.png)"
TOKEN : { <EXTENSION: ("(")? 
			  // some reasonably common Sun ones :
			  (".html" | ".htm" | ".txt" | ".java" | ".class" | ".ps" |
			   ".sxw" | ".sdw" | ".sdd" | ".sxd" | ".sdc" | ".sxc" |
			   ".doc" | ".xls" | ".pdf" | ".au" | ".wav" | ".aiff" |
		           ".mif" | ".sgm" | ".sgml"| ".mpg" | ".midi" | ".gif" |
			   ".png" | ".tiff" | ".jpg" | ".jpeg" | ".pot"| ".tar" | 
			   ".gz"  | ".Z"    | ".uue" | ".sea"  |".zip" | ".gzip" |
			   ".sit" | ".shtm" | ".shtml"| ".properties"  | ".po" |
			   ".msg" | ".cat"  | ".mo"  | ".jar" | ".jjt" | ".js" |
			   ".jse" | ".pl"   | ".dll" | ".asp" | ".cgi" | ".rtf" | 
			   ".xml" | ".bat"  | ".csh" | ".ksh" | ".sh"  | ".cla" |
			   ".o"   | ".cpp"  | ".c"   | ".mp3" | ".obj" | ".ppt" |
			   ".sxi" | ".prc"  | ".pdb" | ".sys" | ".vb"  | ".vbe" |
			   ".c"   |
			   // some rare Sun ones, but that could still come up in docs - not really extensions
			   ".cshrc" | ".login" | ".bashrc" | ".netscape" | ".mozilla" | ".profile" |
			   ".gnome" | "dead.letter" | 
			   // this is a hardware escape sequence used by tip(1) and others - not really
			   // a file extension..
			   "~." |

			   
			   // some more extensions Bob Kuhns pointed me to
			   ".acr" | ".arc" | ".arj" | ".art" |
			   ".ASC" | ".au" | ".avi" | ".avr" | ".avs" | ".bac" |
			   ".bas" | ".BBM" | ".bck" | ".BIG" | ".BIG5" | ".BMF" |
			   ".bmp" | ".BOO" | ".byu" | ".CGM" | "Metafile" | ".clp" |
			   ".cmf" | ".com" | ".cpt" | ".CUR" | ".CUT" | ".dat" |
			   ".des" | ".DCS" | ".DIB" | ".dig" | ".dl" | ".dlg" |
			   ".DMS" | ".dvi" | ".dwc" | ".DWG" | ".dxf" |
			   ".eps" | ".euc" | ".exe" |
			   ".F" | ".fac" | ".fit" | ".flc" | ".fli" | ".flx" |
			   ".fssd" | ".gds" | ".gb" | ".gl" | ".gry" | ".h" |
			   ".ha" | ".ham" | ".hlb" | ".hlp" | ".HPK" | ".hqx" |
			   ".HRZ" | ".HYP" | ".hz" | ".ibm" | ".ice" | ".ico" |
			   ".ief" | ".iff" | "data" | ".IMG" | ".ish" | ".jas" |
			   ".JBIG" | ".JFI" | ".jis" | ".jpc" | ".LBM" | ".lbr" |
			   ".lha" | ".lis" | ".lm8" | ".LZH" | ".LZS" | ".LZX" |
			   ".lzw" | ".MAC" | ".mag" | ".man" | ".map" | ".MAT" |
			   ".md" | ".mgf" | ".mhg" | ".mid" | ".mki" | ".mod" |
			   ".mp2" | ".mpa" | ".mpg" | ".mps" | ".mrb" | ".MSP" |
			   ".MTM" | ".mtv" | ".nbm" |  ".nff" | ".nst" | ".off" | ".omf" |
			   ".pak" | ".pbm" | ".pcd" | ".pcc" | ".pcm" | ".pct" |
			   ".pcx" | ".pds" | ".pgm" | ".pic" | ".pict" | ".pit" |
			   ".pm" | ".pnt" | ".pol" | ".pp" | ".ppm" | ".psid" |
			   ".ras" | ".RAX" | ".RAW" | ".rgb" | ".rmi" | ".rle" |
			   ".ROL" | ".s3m" | ".scx" | ".sdn" | ".sea" | ".sf" |
			   ".sgi" | ".shar" | ".shg" | ".SHK" | ".snd" | ".sqz" |
			   ".stm" | ".tdo" | ".TGA" | ".uc2" | ".ul" | ".UTL" |
			   ".uue" | ".uud" | ".vic" | ".vik" | ".vis" | ".voc" |
			   ".WAV" | ".WMF" | ".XBM" | ".xm" | ".xpm" | ".XWD" |
			   ".Y" | ".yuv" | ".zoo" | ".zw" | ".x" | ".y" | ".X"
                           // .x and .y are actually not filename extensions, but
                           // often appear as part of version numbers (eg.
                           // "Netscape 4.x" ) 
			   )

			   (")")? >}

// do nice things for filenames and the like
TOKEN : { <dotslash: "./" >}
TOKEN : { <slashdot: "/." >}
TOKEN : { <backslashdot: "\\.">}
TOKEN : { <dotbackslash: ".\\">}


/*
300C;LEFT CORNER BRACKET;Ps;0;ON;;;;;Y;OPENING CORNER BRACKET;;;;
300D;RIGHT CORNER BRACKET;Pe;0;ON;;;;;Y;CLOSING CORNER BRACKET;;;;
These 2 are used as quotation marks in zh_tw. And for "double quotation marks" 
which are used in between the above single quotation marks, they are:
300E;LEFT WHITE CORNER BRACKET;Ps;0;ON;;;;;Y;OPENING WHITE CORNER BRACKET;;;;
300F;RIGHT WHITE CORNER BRACKET;Pe;0;ON;;;;;Y;CLOSING WHITE CORNER BRACKET;;;;
*/

/* the QUOTE token originally had the ' character - but now, we're treating
   it like whitespace, to deal with the SunTrans1 idea that the text "it's" should
   be treated as two words !!
   */
TOKEN : { <QUOTE: ["\"","\u300c","\u300d","\u300e","\u300f","\u201d" ] >}
TOKEN : { <QUOTEDWORD: ("\"" | "\u300c" | "\u300d" | "\u300e" | "\u300f" | "\u201d")
            (~[ "'","\t"," ","\b","\f","\n","\r","\"","\u300c","\u300d","\u300e","\u300f", "\u201d" ])+
            ("\"" | "\u300c" | "\u300d" | "\u300e" | "\u300f" | "\u201d" )      >}



// cheating here by adding *terms* to our segmenter (sorry)
TOKEN : { <JumpStart: "JumpStart!" >}
TOKEN : { <crapsoftware: ".NET" >}
// this appears quite often, and there are cases where the <EMAIL> or <URL>
// tokens aren't enough - so I'm putting this in.
TOKEN : { <sundotcom: ".sun.com" >}
TOKEN : { <sunnet: ("Sun.Net" | "My.Sun.Net" | "Access.Sun.Net") >}
TOKEN : { <Yahoo: "Yahoo!" >}

// a few special cases here for common mistakes in documents
TOKEN : { <quoteelipsis: "\"..." >}
// commented out - see note under abbrev() production
//TOKEN : { <dotbracket: ".)" >}
//TOKEN : { <exclambracket: "!)" >}
//TOKEN : { <questionbracket: "?)" >}


// Some bullet lists - not sure abuot this one ?
TOKEN : { <adot: "a." >}
TOKEN : { <bdot: "b." >}
TOKEN : { <cdot: "c." >}
TOKEN : { <ddot: "d." >}
TOKEN : { <edot: "e." >}
TOKEN : { <fdot: "f." >}

TOKEN : { <Adot: "A." >}
TOKEN : { <Bdot: "B." >}
TOKEN : { <Cdot: "C." >}
// D. is already an abbrev !
//TOKEN : { <Ddot: "D." >}
TOKEN : { <Edot: "E." >}
TOKEN : { <Fdot: "F." >}


// Now some abbreviations
TOKEN : { <Abs: "Abs." >}
TOKEN : { <Abstr: "Abstr." >}
TOKEN : { <Add: "Add." >}
TOKEN : { <Approx: "Approx." >}
TOKEN : { <Apr: "Apr." >}
TOKEN : { <Atm: "Atm." >}
TOKEN : { <Aug: "Aug." >}
TOKEN : { <Bill: "Bill." >}
TOKEN : { <Bn: "Bn." >}
TOKEN : { <Bull: "Bull." >}
TOKEN : { <CF: "CF." >}
TOKEN : { <Ca: "Ca." >}
TOKEN : { <Calc: "Calc." >}
TOKEN : { <Capt: "Capt." >}
TOKEN : { <Cdn: "Cdn." >}
TOKEN : { <Cf: "Cf." >}
TOKEN : { <Ch: "Ch." >}
TOKEN : { <Chap: "Chap." >}
TOKEN : { <Coeff: "Coeff." >}
TOKEN : { <Col: "Col." >}
TOKEN : { <Com: "Com." >}
TOKEN : { <Conc: "Conc." >}
TOKEN : { <Cond: "Cond." >}
TOKEN : { <Corp: "Corp." >}
TOKEN : { <D: "D." >}
TOKEN : { <Dec: "Dec." >}
TOKEN : { <Deriv: "Deriv." >}
TOKEN : { <Dia: "Dia." >}
TOKEN : { <Diam: "Diam." >}
TOKEN : { <Din: "Din." >}
TOKEN : { <Dir: "Dir." >}
TOKEN : { <Div: "Div." >}
TOKEN : { <Docs: "Docs." >}
TOKEN : { <Dott: "Dott." >}
TOKEN : { <Dr: "Dr." >}
TOKEN : { <Esp: "Esp." >}
TOKEN : { <Est: "Est." >}
TOKEN : { <Esq: "Esq." >}
TOKEN : { <Exc: "Exc." >}
TOKEN : { <Excl: "Excl." >}
TOKEN : { <FIG: "FIG." >}
TOKEN : { <FIGS: "FIGS." >}
TOKEN : { <Feb: "Feb." >}
TOKEN : { <Fed: "Fed." >}
TOKEN : { <Fig: "Fig." >}
TOKEN : { <Fri: "Fri." >}
TOKEN : { <Govt: "Govt." >}
TOKEN : { <INT: "INT." >}
TOKEN : { <Inc: "Inc." >}
TOKEN : { <INC: "INC." >}
TOKEN : { <Incl: "Incl." >}
TOKEN : { <Ind: "Ind." >}
TOKEN : { <Ing: "Ing." >}
TOKEN : { <Jan: "Jan." >}
TOKEN : { <Jr: "Jr." >}
TOKEN : { <Jul: "Jul." >}
TOKEN : { <Jun: "Jun." >}
TOKEN : { <Ltd: "Ltd." >}
TOKEN : { <MM: "MM." >}
TOKEN : { <MR: "MR." >}
TOKEN : { <MRS: "MRS." >}
TOKEN : { <MS: "MS." >}
TOKEN : { <Mar: "Mar." >}
TOKEN : { <Max: "Max." >}
TOKEN : { <Messrs: "Messrs." >}
TOKEN : { <Mfg: "Mfg." >}
TOKEN : { <Mgr: "Mgr." >}
TOKEN : { <Mill: "Mill." >}
TOKEN : { <Misc: "Misc." >}
TOKEN : { <Mon: "Mon." >}
TOKEN : { <Mr: "Mr." >}
TOKEN : { <Mrs: "Mrs." >}
TOKEN : { <Ms: "Ms." >}
TOKEN : { <Mt: "Mt." >}
TOKEN : { <Nsmallo: "N\u00b0." >}
TOKEN : { <NO: "NO." >}
TOKEN : { <Neg: "Neg." >}
TOKEN : { <No: "No." >}
TOKEN : { <Nos: "Nos." >}
TOKEN : { <Nov: "Nov." >}
TOKEN : { <Obj: "Obj." >}
TOKEN : { <Oct: "Oct." >}
TOKEN : { <Par: "Par." >}
TOKEN : { <Para: "Para." >}
TOKEN : { <Phd: "Ph.D." >}
TOKEN : { <Pos: "Pos." >}
TOKEN : { <Pp: "Pp." >}
TOKEN : { <Prep: "Prep." >}
TOKEN : { <Prof: "Prof." >}
TOKEN : { <Pvt: "Pvt." >}
TOKEN : { <Rec: "Rec." >}
TOKEN : { <Ref: "Ref." >}
TOKEN : { <Reg: "Reg." >}
TOKEN : { <Res: "Res." >}
TOKEN : { <Resp: "Resp." >}
TOKEN : { <Rev: "Rev." >}
TOKEN : { <Sat: "Sat." >}
TOKEN : { <Sep: "Sep." >}
TOKEN : { <Sept: "Sept." >}
TOKEN : { <Sq: "Sq." >}
TOKEN : { <Sr: "Sr." >}
TOKEN : { <St: "St." >}
TOKEN : { <Sta: "Sta." >}
// Sun. seems to end sentences often - and (hopefully)
// is rarely used as an abbreviation within Sun docs <ooer>
//TOKEN : { <Sun: "Sun." >}
TOKEN : { <Suppl: "Suppl." >}
TOKEN : { <Tel: "Tel." >}
TOKEN : { <Tech: "Tech." >}
TOKEN : { <Temp: "Temp." >}
TOKEN : { <Thu: "Thu." >}
TOKEN : { <Thur: "Thur." >}
TOKEN : { <Thurs: "Thurs." >}
TOKEN : { <Tue: "Tue." >}
TOKEN : { <Tues: "Tues." >}
TOKEN : { <Univ: "Univ." >}
TOKEN : { <Util: "Util." >}
TOKEN : { <US: "U.S." >}
TOKEN : { <USA: "U.S.A.">}
TOKEN : { <Viz: "Viz." >}
TOKEN : { <Wed: "Wed." >}
TOKEN : { <abs: "abs." >}
TOKEN : { <abstr: "abstr." >}
TOKEN : { <app: "app." >}
TOKEN : { <appr: "appr." >}
TOKEN : { <approx: "approx." >}
TOKEN : { <apr: "apr." >}
TOKEN : { <atm: "atm." >}
TOKEN : { <aug: "aug." >}
TOKEN : { <bill: "bill." >}
TOKEN : { <bn: "bn." >}
TOKEN : { <bull: "bull." >}
TOKEN : { <ca: "ca." >}
TOKEN : { <calc: "calc." >}
TOKEN : { <capt: "capt." >}
TOKEN : { <cert: "cert." >}
TOKEN : { <cf: "cf." >}
TOKEN : { <chap: "chap." >}
TOKEN : { <circ: "circ." >}
TOKEN : { <coeff: "coeff." >}
TOKEN : { <col: "col." >}
TOKEN : { <com: "com." >}
TOKEN : { <conc: "conc." >}
TOKEN : { <cond: "cond." >}
TOKEN : { <dec: "dec." >}
TOKEN : { <deriv: "deriv." >}
TOKEN : { <dia: "dia." >}
TOKEN : { <diam: "diam." >}
TOKEN : { <din: "din." >}
TOKEN : { <dir: "dir." >}
TOKEN : { <docs: "docs." >}
TOKEN : { <dott: "dott." >}
TOKEN : { <dr: "dr." >}
TOKEN : { <eg: "e.g." >}
TOKEN : { <badeg: "eg." >}
TOKEN : { <esp: "esp." >}
TOKEN : { <est: "est." >}
TOKEN : { <estim: "estim." >}
TOKEN : { <etc: "etc." >}
TOKEN : { <exc: "exc." >}
TOKEN : { <excl: "excl." >}
TOKEN : { <feb: "feb." >}
TOKEN : { <fed: "fed." >}
TOKEN : { <fig: "fig." >}
TOKEN : { <fri: "fri." >}
TOKEN : { <govt: "govt." >}
TOKEN : { <ie: "i.e." >}
TOKEN : { <badie: "ie." >}
TOKEN : { <inc: "inc." >}
TOKEN : { <incl: "incl." >}
TOKEN : { <ind: "ind." >}
TOKEN : { <ing: "ing." >}
TOKEN : { <jan: "jan." >}
TOKEN : { <kg: "kg." >}
TOKEN : { <kh: "km./h.">}
TOKEN : { <kmph: "km.p.h.">}
TOKEN : { <lb: "lb." >}
TOKEN : { <mM: "mM." >}
TOKEN : { <mar: "mar." >}
TOKEN : { <max: "max." >}
TOKEN : { <messrs: "messrs." >}
TOKEN : { <mfg: "mfg." >}
TOKEN : { <mgr: "mgr." >}
TOKEN : { <mill: "mill." >}
TOKEN : { <misc: "misc." >}
TOKEN : { <mon: "mon." >}
TOKEN : { <mr: "mr." >}
TOKEN : { <mrs: "mrs." >}
TOKEN : { <ms: "ms." >}
TOKEN : { <mt: "mt." >}
TOKEN : { <mh: "m./h.">}
TOKEN : { <mph: "m.p.h.">}
TOKEN : { <neg: "neg." >}
TOKEN : { <no: "no." >}
TOKEN : { <nos: "nos." >}
TOKEN : { <nov: "nov." >}
TOKEN : { <oct: "oct." >}
TOKEN : { <oz: "oz." >}
TOKEN : { <pag: "pag." >}
TOKEN : { <par: "par." >}
TOKEN : { <para: "para." >}
TOKEN : { <pos: "pos." >}
TOKEN : { <pp: "pp." >}
TOKEN : { <prep: "prep." >}
TOKEN : { <prof: "prof." >}
TOKEN : { <rec: "rec." >}
TOKEN : { <ref: "ref." >}
TOKEN : { <reg: "reg." >}
TOKEN : { <res: "res." >}
TOKEN : { <resp: "resp." >}
TOKEN : { <rev: "rev." >}
TOKEN : { <sat: "sat." >}
TOKEN : { <sep: "sep." >}
TOKEN : { <sept: "sept." >}
TOKEN : { <sp: "sp." >}
TOKEN : { <spp: "spp." >}
TOKEN : { <sq: "sq." >}
TOKEN : { <st: "st." >}
TOKEN : { <sta: "sta." >}
// see comment for Sun
//TOKEN : { <sun: "sun." >}
TOKEN : { <suppl: "suppl." >}
TOKEN : { <tel: "tel." >}
TOKEN : { <tech: "tech." >}
TOKEN : { <temp: "temp." >}
TOKEN : { <thu: "thu." >}
TOKEN : { <thur: "thur." >}
TOKEN : { <thurs: "thurs." >}
TOKEN : { <tue: "tue." >}
TOKEN : { <tues: "tues." >}
TOKEN : { <univ: "univ." >}
TOKEN : { <util: "util." >}
TOKEN : { <viz: "viz." >}
TOKEN : { <vs: "vs." >}
TOKEN : { <wed: "wed." >}

//TOKEN : { <VERSIONNUMBER: ((["0"-"9"])+ "." (["0"-"9"]".")*)  > }

// hmm - deceptively similar...
TOKEN : { <NUMBER: (["0"-"9"])+ ("."(["0"-"9"])+)* (".")? >}

// this catch all abbrev thing now *doesn't* require a space at the end!
// (before "netscape 2.4.5 readme" was being seen as an abbrev, due to the
//  space - now 2.4.5 gets seen as a number, and isn't counted. This could
// have side effects.
// try and catch other abbreviations
TOKEN : 
{ 
    <ABBREV: ((~["\t"," ","\b","\f","\n","\r",".","!","?","<",">" ] ".")
	      (~["\t"," ","\b","\f","\n","\r",".","!","?","<",">" ] ".")+
	      (~["\t"," ","\b","\f","\n","\r",".","!","?","<",">" ])?) >
}

// Really this should be just "..." but people abuse the poor old elipsis.....
TOKEN : { <ELIPSIS: ("." (".")+)>  }

TOKEN : { <BRACKET: ["(","[","{",    ")","]","}"]>}

/*
Colons - who'd have thought there were this many !
02D0;MODIFIER LETTER TRIANGULAR COLON;Lm;0;L;;;;;N;;;;;
02D1;MODIFIER LETTER HALF TRIANGULAR COLON;Lm;0;L;;;;;N;;;;;
0703;SYRIAC SUPRALINEAR COLON;Po;0;AL;;;;;N;;;;;
0704;SYRIAC SUBLINEAR COLON;Po;0;AL;;;;;N;;;;;
0705;SYRIAC HORIZONTAL COLON;Po;0;AL;;;;;N;;;;;
0706;SYRIAC COLON SKEWED LEFT;Po;0;AL;;;;;N;;;;;
0707;SYRIAC COLON SKEWED RIGHT;Po;0;AL;;;;;N;;;;;
0708;SYRIAC SUPRALINEAR COLON SKEWED LEFT;Po;0;AL;;;;;N;;;;;
0709;SYRIAC SUBLINEAR COLON SKEWED RIGHT;Po;0;AL;;;;;N;;;;;
1365;ETHIOPIC COLON;Po;0;L;;;;;N;;;;;
1366;ETHIOPIC PREFACE COLON;Po;0;L;;;;;N;;;;;
1362;ETHIOPIC FULL STOP;Po;0;L;;;;;N;;;;;
1804;MONGOLIAN COLON;Po;0;ON;;;;;N;;;;;
20A1;COLON SIGN;Sc;0;ET;;;;;N;;;;;
FF1A;FULLWIDTH COLON;Po;0;CS;<wide> 003A;;;;N;;;;;


0589;ARMENIAN FULL STOP;Po;0;L;;;;;N;ARMENIAN PERIOD;;;;
06D4;ARABIC FULL STOP;Po;0;AL;;;;;N;ARABIC PERIOD;;;;
3002;IDEOGRAPHIC FULL STOP;Po;0;ON;;;;;N;IDEOGRAPHIC PERIOD;;;;
30FB;KATAKANA MIDDLE DOT;Pc;0;ON;;;;;N;;;;;
FF01;FULLWIDTH EXCLAMATION MARK;Po;0;ON;<wide> 0021;;;;N;;;;;
FF0E;FULLWIDTH FULL STOP;Po;0;CS;<wide> 002E;;;;N;FULLWIDTH PERIOD;;;;
FF0F;FULLWIDTH SOLIDUS;Po;0;ES;<wide> 002F;;;;N;FULLWIDTH SLASH;;;;
FF1F;FULLWIDTH QUESTION MARK;Po;0;ON;<wide> 003F;;;;N;;;;;
FF61;HALFWIDTH IDEOGRAPHIC FULL STOP;Po;0;ON;<narrow> 3002;;;;N;HALFWIDTH IDEOGRAPHIC PERIOD;;;;
FE52;SMALL FULL STOP;Po;0;CS;<small> 002E;;;;N;SMALL PERIOD;;;;
FE54;SMALL SEMICOLON;Po;0;ON;<small> 003B;;;;N;;;;;
FE55;SMALL COLON;Po;0;CS;<small> 003A;;;;N;;;;;
FE56;SMALL QUESTION MARK;Po;0;ON;<small> 003F;;;;N;;;;;
FE57;SMALL EXCLAMATION MARK;Po;0;ON;<small> 0021;;;;N;;;;;

// more full stops
06EA;ARABIC EMPTY CENTRE LOW STOP;Mn;220;NSM;;;;;N;;;;;
06EB;ARABIC EMPTY CENTRE HIGH STOP;Mn;230;NSM;;;;;N;;;;;
06EC;ARABIC ROUNDED HIGH STOP WITH FILLED CENTRE;Mn;230;NSM;;;;;N;;;;;
0701;SYRIAC SUPRALINEAR FULL STOP;Po;0;AL;;;;;N;;;;;
0702;SYRIAC SUBLINEAR FULL STOP;Po;0;AL;;;;;N;;;;;
1362;ETHIOPIC FULL STOP;Po;0;L;;;;;N;;;;;
1803;MONGOLIAN FULL STOP;Po;0;ON;;;;;N;;;;;
1809;MONGOLIAN MANCHU FULL STOP;Po;0;ON;;;;;N;;;;;


*/

TOKEN :
{
    <SENTSEP: ([".","!","?",":",
	       "\u02d0","\u02d1","\u0703","\u0704","\u0705","\u0706","\u0707",
	       "\u0708","\u0709","\u1365","\u1366","\u1362","\u1804","\u20a1",
	       "\uff1a",

		"\u0589","\u06d4","\u3002","\u30fb","\uff01","\uff0e","\uff0f",
	       "\uff1f","\uff61","\ufe52","\ufe54","\ufe55","\ufe56","\ufe57",
	       
	       "\u06ea","\u06eb","\u06ec","\u0701","\u0702",
	       "\u1362","\u1803","\u1809"

    ]) >
}

// add to allow things like "600-lb. gorilla"
TOKEN : { <DASH: "-">}

// deals with filenames, shared object names and manpage names
TOKEN : { <LETTERDOTNUMBER: (["a"-"z"] | ["A"-"Z"] | "/")*"."(["0"-"9"])+ ("."(["0"-"9"])+)* >}

// a word (well, a string of characters really)
/* the QUOTE token originally had the ' character - but now, we're treating
   it like whitespace, to deal with the SunTrans1 idea that the text "it's" should
   be treated as two words - so the word token needs to exclude ' as a valid word
   
   I'm also not allowing '-' in a word
   */
TOKEN : 
{
    <WORD: (~[ ",","'","\t"," ","\b","\f","\n","\r",".","&","!","?","0"-"9","\"","(","[","{",")","]","}","<",

	     "-",":","\u02d0","\u02d1","\u0703","\u0704","\u0705","\u0706","\u0707",
	     "\u0708","\u0709","\u1365","\u1366","\u1362","\u1804","\u20a1",
	     "\uff1a",

	     "\u0589","\u06d4","\u3002","\u30fb","\uff01","\uff0e","\uff0f",
	     "\uff1f","\uff61","\ufe52","\ufe54","\ufe55","\ufe56","\ufe57",

             "\u06ea","\u06eb","\u06ec","\u0701","\u0702",
	     "\u1362","\u1803","\u1809"

 ])+   
 >
}

TOKEN :
/* for non separating punctuation that shouldn't be counted as a word 
   - just a comma for now */
{  <NONSEPPUNCT: (",")> }

/*
 *  Productions
 */

void file():
{;}
{
    (formatting())? 
    ((formatting())? segment())*
    (formatting())? (<EOF>)?
}

void segment():
{
    String s="";
    String st="";
    Token t;
}
{
    ( (//(ignorednewline())?
       (t=<QUOTE> {s+=t.image;})?
        (

         (t=<BRACKET> {s+=t.image;} st=sentence() {s+=st;} (st=sentsep() {s+=st;})?
          (t=<BRACKET> {s+=t.image;})?) |
         
	 (st=sentence() {s+=st;} 
//         LOOKAHEAD(sentsep() formatting()*)
               (st=sentsep() {s+=st;})? )
         
 	)
       (t=<QUOTE> {s+=t.image;})?
       )  
      |
      st=sentsep() {s+=st;} 
      )
	
	
	{jjtThis.setNodeData(s);}
}

String sentsep():
{
  String s = "";
  Token t;
}
{    
    ( (t=<ELIPSIS> { s+=t.image;}) | 
      (t=<SENTSEP> {s+=t.image;})
    )
	{jjtThis.setNodeData(s); 
	return s;}
}


String sentence():
{
  Token t;
  String s = "";
  String st = "";
}
{
   (t=<numberdot> {s=t.image; System.out.println ("see number dot token");})?

   (
    (
     st=tag() {s+=st;} |
     st=dashedline() {s+=st;} |
     st=dashedword() {s+=st;} |
     st=numabbrev() {s+=st;} |
     st=number() {s+=st;} |
     st=word() {s+=st;} |
     t=<NONSEPPUNCT> {s+=t.image;} |
     t=<BRACKET> {s+=t.image;} | 
     st=ignorednewline() {s+=st;} |
     st=apostrophe() {s+=st;} |
     st=whitespace() {s+=st;}
    )
   )+  { jjtThis.setNodeData(s);
         return s;}
}

// this is for things like "600-lb. gorilla"
String numabbrev():
{
    String s="";
    String st="";
    Token t;
}
{
    (t=<NUMBER> {s=t.image;} t=<DASH> {s+=t.image;} st=abbrev()  {s+=st;}) {return s;}
}

// gets counted as a single word
String dashedword():
{
 String s = "";
 Token t;
}
{
     
     ( (t=<WORD> {s=t.image;} | t=<NUMBER> {s=t.image;})
       (t=<DASH> {s+=t.image;}) 
       (t=<WORD>  { s+=t.image;} | t=<NUMBER> {s+=t.image;})
      )+ 
    
   { jjtThis.setNodeData(s); return s;}

}

// doesn't get word counted
String number():
{
 String s = "";
 String st = "";
 Token t;
}
{     
      (t=<NUMBER> { s=t.image;}) {jjtThis.setNodeData(s);return s;}
}


// gets counted as a single word
String word():
{
 String s = "";
 String st = "";
 Token t;
}
{
    ( 
     (st=numabbrev() {s=st;}) |
     (st=time() {s=st;}) |
     (st=abbrev() {s=st;}) |
     (t=<QUOTEDWORD> {s=t.image;}) | 
     (t=<QUOTE> {s=t.image;}) |
     (st=filename() {s=st;}) |
     (st=email() {s=st;}) |
     (st=url() {s=st;}) |
     (t=<DASH> {s=t.image;}) |
     (t=<WORD>  { s=t.image;}) |
     (st=entity() {s+=st;})|
     (st=amp() {s+=st;})
    )
   { jjtThis.setNodeData(s); return s;}

}

// doesn't get counted
String dashedline():
{
 String s = "";
 Token t;
}
{
     
     t=<DASH> {s+=t.image;} (t=<DASH> {s+=t.image;})+
      
    
   { jjtThis.setNodeData(s); return s;}

}


String bracketedsentence():
{
 String s = "";
 String st = "";
 Token t;
}
{
    ( (t=<BRACKET> {s+=t.image;})
      (
       st=dashedword() {s+=st;} |
       t=<NONSEPPUNCT> {s+=t.image;} |
       st=tag() {s+=st;} |
       st=number() {s+=st;} |
       st=word() {s+=st;} |       
       st=ignorednewline() {s+=st;} |
       st=whitespace() {s+=st;} |
       st=apostrophe() {s+=st;}

       
      )+
      (t=<BRACKET> {s+=t.image;})

    )
   { jjtThis.setNodeData(s); return s;}

}

/*
String versionnumber():
{
    String s = "";
    Token t;
}
{
 (t=<VERSIONNUMBER> {s=t.image;})  { jjtThis.setNodeData(s); return s;}
}
*/
String filename():
{
    Token t;
    String s="";
}{
        (t=<WORD> {s+=t.image;})? t=<EXTENSION> {s+=t.image;}
	{return s;}
}


String email():
{
    Token t;
    String s="";
    String st="";
}{
    
    (t=<EMAIL> {st=t.image; s+=st;})
    
     {return s;}
}

String url():
{
    Token t;
    String s="";
    String st="";
}{
    (t=<URL> {st=t.image; s+=st;})
     {return s;}
}

String time():
{ 
    Token t;
    String s="";
}
{   (t=<TIME> {s+=t.image;}) {return s;}
}

// This production is being used for lots of things now that look like productions
String abbrev():
{
    String s="";
    Token t;
}
{   
    ( (t=<DASH> {s=t.image;})?
     
     // general stuff
     (t=<ABBREV> {s=t.image;})|
     (t=<LETTERDOTNUMBER> {s=t.image;}) |
     (t=<NETDOMAIN> {s=t.image;}) |
     // terms - sorry...
     (t=<JumpStart> {s=t.image;}) |
     (t=<crapsoftware> {s=t.image;}) |
     (t=<Yahoo> {s=t.image;}) |
     (t=<sundotcom> {s=t.image;}) |
     (t=<sunnet> {s=t.image;}) |
     ///(t=<javaclass> {s=t.image;}) |
     // common doc mistakes - sentsep within brackets.
     // Can't use these since when I put them in, sentence like :

     // (Can the segmenter handle parens ?)

     // don't get seen as a segment. This is mutually exclusive with :

     // Note: Handles the bad punctuation '(Not Sun Blue.)' correctly.

     //(t=<dotbracket> {s=t.image;}) |
     //(t=<exclambracket> {s=t.image;}) |
     //(t=<questionbracket> {s=t.image;}) |
     
     (t=<quoteelipsis> {s=t.image;}) |
  
     // bulleted lists ? (yes, I'm only going to "f")
     (t=<adot> {s=t.image;}) |
     (t=<bdot> {s=t.image;}) |
     (t=<cdot> {s=t.image;}) |
     (t=<ddot> {s=t.image;}) |
     (t=<edot> {s=t.image;}) |
     (t=<fdot> {s=t.image;}) |

     (t=<Adot> {s=t.image;}) |
     (t=<Bdot> {s=t.image;}) |
     (t=<Cdot> {s=t.image;}) |
     // D. is already an abbrev below
     //(t=<Ddot> {s=t.image;}) |
     (t=<Edot> {s=t.image;}) |
     (t=<Fdot> {s=t.image;}) |

    
     // real abbreviations
     (t=<Abs> {s=t.image;}) |
     (t=<Abstr> {s=t.image;}) |
     (t=<Add> {s=t.image;}) |
     (t=<Approx> {s=t.image;}) |
     (t=<Apr> {s=t.image;}) |
     (t=<Atm> {s=t.image;}) |
     (t=<Aug> {s=t.image;}) |
     (t=<Bill> {s=t.image;}) |
     (t=<Bn> {s=t.image;}) |
     (t=<Bull> {s=t.image;}) |
     (t=<CF> {s=t.image;}) |
     (t=<Ca> {s=t.image;}) |
     (t=<Calc> {s=t.image;}) |
     (t=<Capt> {s=t.image;}) |
     (t=<Cdn> {s=t.image;}) |
     (t=<Cf> {s=t.image;}) |
     (t=<Ch> {s=t.image;}) |
     (t=<Chap> {s=t.image;}) |
     (t=<Coeff> {s=t.image;}) |
     (t=<Col> {s=t.image;}) |
     (t=<Com> {s=t.image;}) |
     (t=<Conc> {s=t.image;}) |
     (t=<Cond> {s=t.image;}) |
     (t=<Corp> {s=t.image;}) |
     (t=<D> {s=t.image;}) |
     (t=<Dec> {s=t.image;}) |
     (t=<Deriv> {s=t.image;}) |
     (t=<Dia> {s=t.image;}) |
     (t=<Diam> {s=t.image;}) |
     (t=<Din> {s=t.image;}) |
     (t=<Dir> {s=t.image;}) |
     (t=<Div> {s=t.image;}) |
     (t=<Docs> {s=t.image;}) |
     (t=<Dott> {s=t.image;}) |
     (t=<Dr> {s=t.image;}) |
     (t=<Esp> {s=t.image;}) |
     (t=<Est> {s=t.image;}) |
     (t=<Esq> {s=t.image;}) |
     (t=<Exc> {s=t.image;}) |
     (t=<Excl> {s=t.image;}) |
     (t=<FIG> {s=t.image;}) |
     (t=<FIGS> {s=t.image;}) |
     (t=<Feb> {s=t.image;}) |
     (t=<Fed> {s=t.image;}) |
     (t=<Fig> {s=t.image;}) |
     (t=<Fri> {s=t.image;}) |
     (t=<Govt> {s=t.image;}) |
     (t=<INT> {s=t.image;}) |
     (t=<Inc> {s=t.image;}) |
     (t=<INC> {s=t.image;}) |
     (t=<Incl> {s=t.image;}) |
     (t=<Ind> {s=t.image;}) |
     (t=<Ing> {s=t.image;}) |
     (t=<Jan> {s=t.image;}) |
     (t=<Jr> {s=t.image;}) |
     (t=<Jul> {s=t.image;}) |
     (t=<Jun> {s=t.image;}) |
     (t=<Ltd> {s=t.image;}) |
     (t=<MM> {s=t.image;}) |
     (t=<MR> {s=t.image;}) |
     (t=<MRS> {s=t.image;}) |
     (t=<MS> {s=t.image;}) |
     (t=<Mar> {s=t.image;}) |
     (t=<Max> {s=t.image;}) |
     (t=<Messrs> {s=t.image;}) |
     (t=<Mfg> {s=t.image;}) |
     (t=<Mgr> {s=t.image;}) |
     (t=<Mill> {s=t.image;}) |
     (t=<Misc> {s=t.image;}) |
     (t=<Mon> {s=t.image;}) |
     (t=<Mr> {s=t.image;}) |
     (t=<Mrs> {s=t.image;}) |
     (t=<Ms> {s=t.image;}) |
     (t=<Mt> {s=t.image;}) |
     (t=<Nsmallo> {s=t.image;}) |
     (t=<NO> {s=t.image;}) |
     (t=<Neg> {s=t.image;}) |
     (t=<No> {s=t.image;}) |
     (t=<Nos> {s=t.image;}) |
     (t=<Nov> {s=t.image;}) |
     (t=<Obj> {s=t.image;}) |
     (t=<Oct> {s=t.image;}) |
     (t=<Par> {s=t.image;}) |
     (t=<Para> {s=t.image;}) |
     (t=<Phd> {s=t.image;}) |
     (t=<Pos> {s=t.image;}) |
     (t=<Pp> {s=t.image;}) |
     (t=<Prep> {s=t.image;}) |
     (t=<Prof> {s=t.image;}) |
     (t=<Pvt> {s=t.image;}) |
     (t=<Rec> {s=t.image;}) |
     (t=<Ref> {s=t.image;}) |
     (t=<Reg> {s=t.image;}) |
     (t=<Res> {s=t.image;}) |
     (t=<Resp> {s=t.image;}) |
     (t=<Rev> {s=t.image;}) |
     (t=<Sat> {s=t.image;}) |
     (t=<Sep> {s=t.image;}) |
     (t=<Sept> {s=t.image;}) |
     (t=<Sq> {s=t.image;}) |
     (t=<Sr> {s=t.image;}) |
     (t=<St> {s=t.image;}) |
     (t=<Sta> {s=t.image;}) |
     // Hacking out the name of our esteemed company
     // I wonder could we re-spell "Sunday" to "Sughnday"
     // to avoid this confusion ?
     //     (t=<Sun> {s=t.image;}) |
     (t=<Suppl> {s=t.image;}) |
     (t=<Tel> {s=t.image;}) |
     (t=<Tech> {s=t.image;}) |
     (t=<Temp> {s=t.image;}) |
     (t=<Thu> {s=t.image;}) |
     (t=<Thur> {s=t.image;}) |
     (t=<Thurs> {s=t.image;}) |
     (t=<Tue> {s=t.image;}) |
     (t=<Tues> {s=t.image;}) |
     (t=<Univ> {s=t.image;}) |
     (t=<Util> {s=t.image;}) |
     (t=<US> {s=t.image;}) |
     (t=<USA> {s=t.image;}) |
     (t=<Viz> {s=t.image;}) |
     (t=<Wed> {s=t.image;}) |
     (t=<abs> {s=t.image;}) |
     (t=<abstr> {s=t.image;}) |
     (t=<app> {s=t.image;}) |
     (t=<appr> {s=t.image;}) |
     (t=<approx> {s=t.image;}) |
     (t=<apr> {s=t.image;}) |
     (t=<atm> {s=t.image;}) |
     (t=<aug> {s=t.image;}) |
     (t=<bill> {s=t.image;}) |
     (t=<bn> {s=t.image;}) |
     (t=<bull> {s=t.image;}) |
     (t=<ca> {s=t.image;}) |
     (t=<calc> {s=t.image;}) |
     (t=<capt> {s=t.image;}) |
     (t=<cert> {s=t.image;}) |
     (t=<cf> {s=t.image;}) |
     (t=<chap> {s=t.image;}) |
     (t=<circ> {s=t.image;}) |
     (t=<coeff> {s=t.image;}) |
     (t=<col> {s=t.image;}) |
     (t=<com> {s=t.image;}) |
     (t=<conc> {s=t.image;}) |
     (t=<cond> {s=t.image;}) |
     (t=<dec> {s=t.image;}) |
     (t=<deriv> {s=t.image;}) |
     (t=<dia> {s=t.image;}) |
     (t=<diam> {s=t.image;}) |
     (t=<din> {s=t.image;}) |
     (t=<dir> {s=t.image;}) |
     (t=<docs> {s=t.image;}) |
     (t=<dott> {s=t.image;}) |
     (t=<dr> {s=t.image;}) |
     (t=<eg> {s=t.image;}) |
     (t=<badeg> {s=t.image;}) |
     (t=<esp> {s=t.image;}) |
     (t=<est> {s=t.image;}) |
     (t=<estim> {s=t.image;}) |
     (t=<etc> {s=t.image;}) |
     (t=<exc> {s=t.image;}) |
     (t=<excl> {s=t.image;}) |
     (t=<feb> {s=t.image;}) |
     (t=<fed> {s=t.image;}) |
     (t=<fig> {s=t.image;}) |
     (t=<fri> {s=t.image;}) |
     (t=<govt> {s=t.image;}) |
     (t=<ie> {s=t.image;}) |
     (t=<badie> {s=t.image;}) |
     (t=<inc> {s=t.image;}) |
     (t=<incl> {s=t.image;}) |
     (t=<ind> {s=t.image;}) |
     (t=<ing> {s=t.image;}) |
     (t=<jan> {s=t.image;}) |
     (t=<kg> {s=t.image;}) |
     (t=<kh> {s=t.image;}) |
     (t=<kmph> {s=t.image;}) |
     (t=<lb> {s=t.image;}) |
     (t=<mh> {s=t.image;}) |
     (t=<mph> {s=t.image;}) |
     (t=<mM> {s=t.image;}) |
     (t=<mar> {s=t.image;}) |
     (t=<max> {s=t.image;}) |
     (t=<messrs> {s=t.image;}) |
     (t=<mfg> {s=t.image;}) |
     (t=<mgr> {s=t.image;}) |
     (t=<mill> {s=t.image;}) |
     (t=<misc> {s=t.image;}) |
     (t=<mon> {s=t.image;}) |
     (t=<mr> {s=t.image;}) |
     (t=<mrs> {s=t.image;}) |
     (t=<ms> {s=t.image;}) |
     (t=<mt> {s=t.image;}) |
     (t=<neg> {s=t.image;}) |
     (t=<no> {s=t.image;}) |
     (t=<nos> {s=t.image;}) |
     (t=<nov> {s=t.image;}) |
     (t=<oct> {s=t.image;}) |
     (t=<oz> {s=t.image;}) |
   
     (t=<pag> {s=t.image;}) |
     (t=<par> {s=t.image;}) |
     (t=<para> {s=t.image;}) |
     (t=<pos> {s=t.image;}) |
     (t=<pp> {s=t.image;}) |
     (t=<prep> {s=t.image;}) |
     (t=<prof> {s=t.image;}) |
     (t=<rec> {s=t.image;}) |
     (t=<ref> {s=t.image;}) |
     (t=<reg> {s=t.image;}) |
     (t=<res> {s=t.image;}) |
     (t=<resp> {s=t.image;}) |
     (t=<rev> {s=t.image;}) |
     (t=<sat> {s=t.image;}) |
     (t=<sep> {s=t.image;}) |
     (t=<sept> {s=t.image;}) |
     (t=<sp> {s=t.image;}) |
     (t=<spp> {s=t.image;}) |
     (t=<sq> {s=t.image;}) |
     (t=<st> {s=t.image;}) |
     (t=<sta> {s=t.image;}) |
     // removing this !
     //(t=<sun> {s=t.image;}) |
     (t=<suppl> {s=t.image;}) |
     (t=<tel> {s=t.image;}) |
     (t=<tech> {s=t.image;}) |
     (t=<temp> {s=t.image;}) |
     (t=<thu> {s=t.image;}) |
     (t=<thur> {s=t.image;}) |
     (t=<thurs> {s=t.image;}) |
     (t=<tue> {s=t.image;}) |
     (t=<tues> {s=t.image;}) |
     (t=<univ> {s=t.image;}) |
     (t=<util> {s=t.image;}) |
     (t=<viz> {s=t.image;}) |
     (t=<vs> {s=t.image;}) |
     (t=<wed> {s=t.image;}) |

     (t=<backslashdot> {s=t.image;}) |
     (t=<dotbackslash> {s=t.image;}) |
     (t=<dotslash> {s=t.image;}) |
     (t=<slashdot> {s=t.image;})) { jjtThis.setNodeData(s); return s;}
}


String whitespace():
{
 String s = "";
 Token t;
}
{
  (t=<WS> { s+=t.image;})+ { jjtThis.setNodeData(s);return s;}

}


String formatting():
{
    String s="";
    Token t;
}
{ 
    (
     (t=<FORMATTING> { s+=t.image;}) | 
     (t=<WS> {s+=t.image;}))+ { jjtThis.setNodeData(s);return s;}  
 
}
 
String ignorednewline():
{
    String s="";
    Token t;
}
{ 
    /*((t=<SLASHNSPACE> {s+=" ";}) |   Oh dear - this appears to be doing whitespace normalisation :-(*/
     ((t=<SLASHNSPACE> {s+=t.image;}) |
     (t=<FORMATTING> { s+=t.image;})+){ jjtThis.setNodeData(s);return s;}  
 
} 


// Html/Sgml/Xml workarounds - lifted from the SgmlDocFragmentParser

String tag() :
{
  Token t;
  String s = "";
}
{ (t=<TAG> {s+=t.image; } ) {jjtThis.setNodeData(s); return s; }
}

String entity():
{
    String s="";
    Token t;
}
{ // Html/Sgml/Xml workarounds
    
    (t=<entity>  {s=t.image;}) {jjtThis.setNodeData(s);return s;}
}

String amp():
{
    String s="";
    Token t;
}
{ // Html/Sgml/Xml workarounds
    (t=<AMP> {s=t.image;}) {jjtThis.setNodeData(s);return s;}
}

// a special production for apostrophe.
/* For the text "Please click the 'bold:' button."
   before, apostrophe was seen as whitespace, to make 
   "it's" be seen as two word nodes, and get wordcounted twice.
   However, there's also a notion that whitespace after a sentence
   separator should be seen as formatting. In the first example above,
   after "...bold:" we'd get a sentence separator, and the following
   apostrophe would disappear into the skeleton file as formatting.
   Instead, we now have an APOSTROPHE token that's separate to the WS
   token to prevent this from happening
*/
String apostrophe():
{    String s="";
     Token t;
}{
     (t=<APOSTROPHE> {s=t.image;}) {jjtThis.setNodeData(s); return s;}
}
