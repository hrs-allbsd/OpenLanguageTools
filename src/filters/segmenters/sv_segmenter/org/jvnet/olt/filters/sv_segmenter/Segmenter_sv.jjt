
/*
 * Copyright  2005 Sun Microsystems, Inc. 
 * All rights reserved Use is subject to license terms.
 *
 */

options{
    NODE_PACKAGE = "org.jvnet.olt.filters.sv_segmenter";
    LOOKAHEAD=4;
    VISITOR = true;
    FORCE_LA_CHECK = true;
    STATIC = false;
    UNICODE_INPUT=true;
    JAVA_UNICODE_ESCAPE = false;

}

PARSER_BEGIN(Segmenter_sv)

package org.jvnet.olt.filters.sv_segmenter;

/** 

  This sentence segmenter is designed to run on Sun Microsystems Inc. documentation
  - as a result, it's quite biased towards technical material, and has a few things
  builtin to deal with these nicely.

*/

// import java.io.*;


public class Segmenter_sv {

  /**
   *  A static method to allow the SCCS version of the file to be read at 
   *  runtime.
   */
  public static final String getVersionInfo()
  {
    return "Swedish Segmenter - version: 1.0";
  }

  protected boolean boolParsed = false;

  /**
   *  The method is called by other classes to parse the
   *  current input stream.
   *  @exception  ParseException
   */
  public void parse() throws ParseException
  {
    //  Call top level rule.
    file();
    boolParsed = true;
  }

  /**
   *  walkParseTree:  This method provides an interface to allow node Visitors
   *  to be passed to the parse tree generated by this parser. 
   *  @param  visitor The visitor to act on all the nodes in the parse tree.
   *  @param  data    An object to be used as an aid to the tree walk.
   *  @exception Exception
   */
  public void walkParseTree(Segmenter_svVisitor visitor, Object data) throws Exception
  {
    if(boolParsed && (visitor != null))
    {
      //  Get root node of the parse tree
      SimpleNode node =(SimpleNode) jjtree.rootNode();
      node.jjtAccept(visitor, data);
    }
    else
    {
      //  Throw an exception
      throw new Exception("Input stream not parsed");
    }
  }
  protected void finalize() throws Throwable
  {
    super.finalize();
  }
}

PARSER_END(Segmenter_sv)

TOKEN : { <numberdot: "\n" (" "| "\t" | "\f")* ("1." | "2." | "3." | "4." | "5." | "6." | "7." | "8.") >}

TOKEN : {<SLASHNSPACE: (("\n" | "\r\n") ([" ","\t"])+) >}


// whitespace characters
/* the QUOTE token originally had the ' character - but now, we're treating
   it like whitespace, to deal with the SunTrans1 idea that the text "it's" should
   be treated as two words !!
   */
TOKEN :
{
  <WS: (" " |
	"\t" |
	"\b" |
	"\f" |
        "'"
	/*	"\n" | 
		"\r"*/
)+ > 
}

TOKEN : { <FORMATTING: ("\n" | "\r")+ > }

// this is a *very* special case - I'm teaching the segmenter about tags, basically
// it should now ignore anything between <..> : thus, it's now important to send
// all tagged text through the segmenter like this - any plaintext that's supposed
// to have tags should have them converted to &lt;...&gt;

/*  Tags and bracket tokens */
TOKEN :
{
	<STAGO:	     "<"				>	: TAG
|	<ETAGO:	     "</"				>	: TAG
|       <GT:         ">"  >
}

<TAG>
TOKEN :
{
        <#ALPHA:	["a"-"z","A"-"Z","_","-","."]	>
|	<#NUM:		["0"-"9"]			>
|	<#ALPHANUM:	<ALPHA> | <NUM>			>        
|       <TAGNAME:       <ALPHA> ( <ALPHANUM> )*         >   : ATTLIST 
}

<TAG, ATTLIST>
TOKEN :
{
    <TAGC:		">"				>	: DEFAULT
}

<TAG, ATTLIST>
TOKEN :
{
    <TAGWS:		(["\r","\n","\b","\f"," ","\t"])+	>
}

<ATTLIST> TOKEN :
{  <#STRING_LIT: "'" ( ~["'"] )* "'" | "\"" ( ~["\""] )* "\""  >
|  <ATTRIBS:       (  <STRING_LIT> | ~[ ">", "\"", "'" ] )+    >
}


// We never segment inside entities like &this.entity; Actually, what happens
// here is that an entity token can suck up the next tag if necessary - but
// the result it the same,
// in that we never segment within an entity. Entities end with one of 
// " " ";" "\n" "\r" and that's all.

TOKEN :
{
  <entity: ( "&" | "%" ) ( ~["<" , " " , "\t" , "\n", "\r", ";" ] )+ (";")? >
}

TOKEN :
{
  <AMP: "&" >
}



// attempt to deal with email addresses
TOKEN :{
    <EMAIL: ((~[ ";","/",":","&","=","+","$",",","[","]","\t"," ","\b","\f","\n","\r","@","!","?","\"" ])+
	    "@"
	    (~[ ";","/",":","&","=","+","$",",","[","]","\t"," ","\b","\f","\n","\r","@","!","?","\"" ])+)
            (~[ ";","/",":","&","=","+","$",",","[","]","\t"," ","\b","\f","\n","\r","@","!","?","\"","." ])>
}

// attempt to deal with urls
TOKEN : { <URL: ("http://" | "ftp://" | "https://" | "file://" ) 
	    (~[ ";",",","[","]","{","}","(",")",">","<","\t"," ","\b","\f","\n","\r" ])*
	    (~[ ";",",","[","]","{","}","(",")",">","<","\t"," ","\b","\f","\n","\r","." ])
		    
		    >
}

// Something to detect strings like Thu Sep 12 16:24:41 BST 2002
TOKEN : { <TIME: (["0"-"9"])+":"(((["0"-"9"])+":") | ((["0"-"9"])+))+ >
}



// attempt to catch machine/domain names
// note that ".info" is also a filename extension ! be sure not to add it twice :-)
TOKEN : { <NETDOMAIN: (".com" | ".net" | ".co" | ".gov" | ".mil" |
		       ".edu"| ".org"| ".COM" |
		       // "New" TLDs from http://www.icann.org/tlds/
		       ".biz" | ".info" | ".aero" |
		       ".coop" | ".museum" | ".name" | ".pro"
  // This list of country TLDs is from http://www.iana.org/cctld/cctld-whois.htm
  // I might trim this down a bit if the sheer number of these slow down
  // the lexer too much.
 ".ac" | ".ad" | ".ae" | ".af" | ".ag" | ".ai" | ".al" | ".am" |
 ".an" | ".ao" | ".aq" | ".ar" | ".as" | ".at" | ".au" | ".aw" |
 ".az" | ".ba" | ".bb" | ".bd" | ".be" | ".bf" | ".bg" | ".bh" |
 ".bi" | ".bj" | ".bm" | ".bn" | ".bo" | ".br" | ".bs" | ".bt" |
 ".bv" | ".bw" | ".by" | ".bz" | ".ca" | ".cc" | ".cd" | ".cf" |
 ".cg" | ".ch" | ".ci" | ".ck" | ".cl" | ".cm" | ".cn" | ".co" |
 ".cr" | ".cu" | ".cv" | ".cx" | ".cy" | ".cz" | ".de" | ".dj" |
 ".dk" | ".dm" | ".do" | ".dz" | ".ec" | ".ee" | ".eg" | ".eh" |
 ".er" | ".es" | ".et" | ".fi" | ".fj" | ".fk" | ".fm" | ".fo" |
 ".fr" | ".ga" | ".gd" | ".ge" | ".gf" | ".gg" | ".gh" | ".gi" |
 ".gl" | ".gm" | ".gn" | ".gp" | ".gq" | ".gr" | ".gs" | ".gt" |
 ".gu" | ".gw" | ".gy" | ".hk" | ".hm" | ".hn" | ".hr" | ".ht" |
 ".hu" | ".id" | ".ie" | ".il" | ".im" | ".in" | ".io" | ".iq" |
 ".ir" | ".is" | ".it" | ".je" | ".jm" | ".jo" | ".jp" | ".ke" |
 ".kg" | ".kh" | ".ki" | ".km" | ".kn" | ".kp" | ".kr" | ".kw" |
 ".ky" | ".kz" | ".la" | ".lb" | ".lc" | ".li" | ".lk" | ".lr" |
 ".ls" | ".lt" | ".lu" | ".lv" | ".ly" | ".ma" | ".mc" | ".md" |
 ".mg" | ".mh" | ".mk" | ".ml" | ".mm" | ".mn" | ".mo" | ".mp" |
 ".mq" | ".mr" | ".ms" | ".mt" | ".mu" | ".mv" | ".mw" | ".mx" |
 ".my" | ".mz" | ".na" | ".nc" | ".ne" | ".nf" | ".ng" | ".ni" |
 ".nl" | ".no" | ".np" | ".nr" | ".nu" | ".nz" | ".om" | ".pa" |
 ".pe" | ".pf" | ".pg" | ".ph" | ".pk" | ".pl" | ".pm" | ".pn" |
 ".pr" | ".ps" | ".pt" | ".pw" | ".py" | ".qa" | ".re" | ".ro" |
 ".ru" | ".rw" | ".sa" | ".sb" | ".sc" | ".sd" | ".se" | ".sg" |
 ".sh" | ".si" | ".sj" | ".sk" | ".sl" | ".sm" | ".sn" | ".so" |
 ".sr" | ".st" | ".sv" | ".sy" | ".sz" | ".tc" | ".td" | ".tf" |
 ".tg" | ".th" | ".tj" | ".tk" | ".tm" | ".tn" | ".to" | ".tp" |
 ".tr" | ".tt" | ".tv" | ".tw" | ".tz" | ".ua" | ".ug" | ".uk" |
 ".um" | ".us" | ".uy" | ".uz" | ".va" | ".vc" | ".ve" | ".vg" |
 ".vi" | ".vn" | ".vu" | ".wf" | ".ws" | ".ye" | ".yt" | ".yu"

		       ) >}


// Attempt to catch regularly occuring filename extensions
// - I'm adding brackets here, since these extensions are often
// in brackets like "the portable network graphics format (.png)"
TOKEN : { <EXTENSION: ("(")? 
			  // some reasonably common Sun ones :
			  (".html" | ".htm" | ".txt" | ".java" | ".class" | ".ps" |
			   ".sxw" | ".sdw" | ".sdd" | ".sxd" | ".sdc" | ".sxc" |
			   ".doc" | ".xls" | ".pdf" | ".au" | ".wav" | ".aiff" |
		           ".mif" | ".sgm" | ".sgml"| ".mpg" | ".midi" | ".gif" |
			   ".png" | ".tiff" | ".jpg" | ".jpeg" | ".pot"| ".tar" | 
			   ".gz"  | ".Z"    | ".uue" | ".sea"  |".zip" | ".gzip" |
			   ".sit" | ".shtm" | ".shtml"| ".properties"  | ".po" |
			   ".msg" | ".cat"  | ".mo"  | ".jar" | ".jjt" | ".js" |
			   ".jse" | ".pl"   | ".dll" | ".asp" | ".cgi" | ".rtf" | 
			   ".xml" | ".bat"  | ".csh" | ".ksh" | ".sh"  | ".cla" |
			   ".o"   | ".cpp"  | ".c"   | ".mp3" | ".obj" | ".ppt" |
			   ".sxi" | ".prc"  | ".pdb" | ".sys" | ".vb"  | ".vbe" |
			   ".c"   |
			   // some rare Sun ones, but that could still come up in docs - not really extensions
			   ".cshrc" | ".login" | ".bashrc" | ".netscape" | ".mozilla" | ".profile" |
			   ".gnome" | "dead.letter" | 
			   // this is a hardware escape sequence used by tip(1) and others - not really
			   // a file extension..
			   "~." |

			   
			   // some more extensions Bob Kuhns pointed me to
			   ".acr" | ".arc" | ".arj" | ".art" |
			   ".ASC" | ".au" | ".avi" | ".avr" | ".avs" | ".bac" |
			   ".bas" | ".BBM" | ".bck" | ".BIG" | ".BIG5" | ".BMF" |
			   ".bmp" | ".BOO" | ".byu" | ".CGM" | "Metafile" | ".clp" |
			   ".cmf" | ".com" | ".cpt" | ".CUR" | ".CUT" | ".dat" |
			   ".des" | ".DCS" | ".DIB" | ".dig" | ".dl" | ".dlg" |
			   ".DMS" | ".dvi" | ".dwc" | ".DWG" | ".dxf" |
			   ".eps" | ".euc" | ".exe" |
			   ".F" | ".fac" | ".fit" | ".flc" | ".fli" | ".flx" |
			   ".fssd" | ".gds" | ".gb" | ".gl" | ".gry" | ".h" |
			   ".ha" | ".ham" | ".hlb" | ".hlp" | ".HPK" | ".hqx" |
			   ".HRZ" | ".HYP" | ".hz" | ".ibm" | ".ice" | ".ico" |
			   ".ief" | ".iff" | "data" | ".IMG" | ".ish" | ".jas" |
			   ".JBIG" | ".JFI" | ".jis" | ".jpc" | ".LBM" | ".lbr" |
			   ".lha" | ".lis" | ".lm8" | ".LZH" | ".LZS" | ".LZX" |
			   ".lzw" | ".MAC" | ".mag" | ".man" | ".map" | ".MAT" |
			   ".md" | ".mgf" | ".mhg" | ".mid" | ".mki" | ".mod" |
			   ".mp2" | ".mpa" | ".mpg" | ".mps" | ".mrb" | ".MSP" |
			   ".MTM" | ".mtv" | ".nbm" | ".nff" | ".nst" | ".off" | ".omf" |
			   ".pak" | ".pbm" | ".pcd" | ".pcc" | ".pcm" | ".pct" |
			   ".pcx" | ".pds" | ".pgm" | ".pic" | ".pict" | ".pit" |
			   ".pm" | ".pnt" | ".pol" | ".pp" | ".ppm" | ".psid" |
			   ".ras" | ".RAX" | ".RAW" | ".rgb" | ".rmi" | ".rle" |
			   ".ROL" | ".s3m" | ".scx" | ".sdn" | ".sea" | ".sf" |
			   ".sgi" | ".shar" | ".shg" | ".SHK" | ".snd" | ".sqz" |
			   ".stm" | ".tdo" | ".TGA" | ".uc2" | ".ul" | ".UTL" |
			   ".uue" | ".uud" | ".vic" | ".vik" | ".vis" | ".voc" |
			   ".WAV" | ".WMF" | ".XBM" | ".xm" | ".xpm" | ".XWD" |
			   ".Y" | ".yuv" | ".zoo" | ".zw" |".x" | ".y" | ".X"
                           // .x and .y are actually not filename extensions, but
                           // often appear as part of version numbers (eg.
                           // "Netscape 4.x" ) 
			   )

			   (")")? >}

// do nice things for filenames and the like
TOKEN : { <dotslash: "./" >}
TOKEN : { <slashdot: "/." >}
TOKEN : { <backslashdot: "\\.">}
TOKEN : { <dotbackslash: ".\\">}

/*
300C;LEFT CORNER BRACKET;Ps;0;ON;;;;;Y;OPENING CORNER BRACKET;;;;
300D;RIGHT CORNER BRACKET;Pe;0;ON;;;;;Y;CLOSING CORNER BRACKET;;;;
These 2 are used as quotation marks in zh_tw. And for "double quotation marks" 
which are used in between the above single quotation marks, they are:
300E;LEFT WHITE CORNER BRACKET;Ps;0;ON;;;;;Y;OPENING WHITE CORNER BRACKET;;;;
300F;RIGHT WHITE CORNER BRACKET;Pe;0;ON;;;;;Y;CLOSING WHITE CORNER BRACKET;;;;
docbook sgml uses this
201D;RIGHT DOUBLE QUOTATION MARK;Pf;0;ON;;;;;N;DOUBLE COMMA QUOTATION MARK;;;;
and normal " for &rdquor; and $rdquo;

*/

/* the QUOTE token originally had the ' character - but now, we're treating
   it like whitespace, to deal with the SunTrans1 idea that the text "it's" should
   be treated as two words !!
   */
TOKEN : { <QUOTE: ["\"","\u300c","\u300d","\u300e","\u300f","\u201d" ] >}
TOKEN : { <QUOTEDWORD: ("\"" | "\u300c" | "\u300d" | "\u300e" | "\u300f" | "\u201d")
            (~[ "'","\t"," ","\b","\f","\n","\r","\"","\u300c","\u300d","\u300e","\u300f", "\u201d" ])+
            ("\"" | "\u300c" | "\u300d" | "\u300e" | "\u300f" | "\u201d" )      >}



// cheating here by adding *terms* to our segmenter (sorry)
TOKEN : { <JumpStart: "JumpStart!" >}
TOKEN : { <crapsoftware: ".NET" >}
// this appears quite often, and there are cases where the <EMAIL> or <URL>
// tokens aren't enough - so I'm putting this in.
TOKEN : { <sundotcom: ".sun.com" >}
TOKEN : { <sunnet: ("Sun.Net" | "My.Sun.Net" | "Access.Sun.Net") >}
TOKEN : { <Yahoo: "Yahoo!" >}


// I thought I'd add the names of the main jav package names too. 
//(this is was actually triggering a java compiler bug, so I had to remove it ! :-)
// - these might prove useful though if we're segmenting java help stuff....
/*TOKEN : { <javaclass: ("com.sun.")? ("java.applet" |"java.awt" |"java.awt.color" |"java.awt.datatransfer" |		       "java.awt.dnd" |"java.awt.event" |"java.awt.font" |"java.awt.geom" |
		       "java.awt.im" |"java.awt.im.spi" |"java.awt.image" |"java.awt.image.renderable" |
		       "java.awt.print" |"java.beans" |"java.beans.beancontext" |"java.io" |
		       "java.lang" |"java.lang.ref" |"java.lang.reflect" |"java.math" |"java.net" |
		       "java.nio" |"java.nio.channels" |"java.nio.channels.spi" |"java.nio.charset" |
		       "java.nio.charset.spi" |"java.rmi" |"java.rmi.activation" |"java.rmi.dgc" |
		       "java.rmi.registry" |"java.rmi.server" |"java.security" |"java.security.acl" |
		       "java.security.cert" |"java.security.interfaces" |"java.security.spec" |
		       "java.sql" |"java.text" |"java.util" |"java.util.jar" |"java.util.logging" |
		       "java.util.prefs" |"java.util.regex" |"java.util.zip" |"javax.accessibility" |
		       "javax.crypto" |"javax.crypto.interfaces" |"javax.crypto.spec" |"javax.imageio" |
		       "javax.imageio.event" |"javax.imageio.metadata" |"javax.imageio.plugins.jpeg" |
		       "javax.imageio.spi" |"javax.imageio.stream" |"javax.naming" |"javax.naming.directory" |
		       "javax.naming.event" |"javax.naming.ldap" |"javax.naming.spi" |"javax.net" |
		       "javax.net.ssl" |"javax.print" |"javax.print.attribute" |
		       "javax.print.attribute.standard" |"javax.print.event" |"javax.rmi" |
		       "javax.rmi.CORBA" |"javax.security.auth" |"javax.security.auth.callback" |
		       "javax.security.auth.kerberos" |"javax.security.auth.login" |
		       "javax.security.auth.spi" |"javax.security.auth.x500" |"javax.security.cert" |
		       "javax.sound.midi" |"javax.sound.midi.spi" |"javax.sound.sampled" |
		       "javax.sound.sampled.spi" |"javax.sql" |"javax.swing" |"javax.swing.border" |
		       "javax.swing.colorchooser" |"javax.swing.event" |"javax.swing.filechooser" |
		       "javax.swing.plaf" |"javax.swing.plaf.basic" |"javax.swing.plaf.metal" |
		       "javax.swing.plaf.multi" |"javax.swing.table" |"javax.swing.text" |
		       "javax.swing.text.html" |"javax.swing.text.html.parser" |"javax.swing.text.rtf" |
		       "javax.swing.tree" |"javax.swing.undo" |"javax.transaction" |"javax.transaction.xa" |
		       "javax.xml.parsers" |"javax.xml.transform" |"javax.xml.transform.dom" |
		       "javax.xml.transform.sax" |"javax.xml.transform.stream" |"org.ietf.jgss" |
		       "org.omg.CORBA" |"org.omg.CORBA_2_3" |"org.omg.CORBA_2_3.portable" |
		       "org.omg.CORBA.DynAnyPackage" |"org.omg.CORBA.ORBPackage" |
		       "org.omg.CORBA.portable" |"org.omg.CORBA.TypeCodePackage" |
		       "org.omg.CosNaming" |"org.omg.CosNaming.NamingContextExtPackage" |
		       "org.omg.CosNaming.NamingContextPackage" |"org.omg.Dynamic" |"org.omg.DynamicAny" |
		       "org.omg.DynamicAny.DynAnyFactoryPackage" |"org.omg.DynamicAny.DynAnyPackage" |
		       "org.omg.IOP" |"org.omg.IOP.CodecFactoryPackage" |"org.omg.IOP.CodecPackage" |
		       "org.omg.Messaging" |"org.omg.PortableInterceptor" |
		       "org.omg.PortableInterceptor.ORBInitInfoPackage" |"org.omg.PortableServer" |
		       "org.omg.PortableServer.CurrentPackage" |"org.omg.PortableServer.POAManagerPackage" |
		       "org.omg.PortableServer.POAPackage" |"org.omg.PortableServer.portable" |
		       "org.omg.PortableServer.ServantLocatorPackage" |"org.omg.SendingContext" |
		       "org.omg.stub.java.rmi" |"org.w3c.dom" |"org.xml.sax" |"org.xml.sax.ext" |
		       "org.xml.sax.helpers" | "System" | "Thread" | "String" ) (".")? >}
*/



// a few special cases here for common mistakes in documents
TOKEN : { <quoteelipsis: "\"..." >}
// commented out - see note under abbrev() production
//TOKEN : { <dotbracket: ".)" >}
//TOKEN : { <exclambracket: "!)" >}
//TOKEN : { <questionbracket: "?)" >}


// Some bullet lists - not sure abuot this one ?
TOKEN : { <adot: "a." >}
TOKEN : { <bdot: "b." >}
TOKEN : { <cdot: "c." >}
TOKEN : { <ddot: "d." >}
TOKEN : { <edot: "e." >}
TOKEN : { <fdot: "f." >}

TOKEN : { <Adot: "A." >}
TOKEN : { <Bdot: "B." >}
TOKEN : { <Cdot: "C." >}
// D. is already an abbrev !
//TOKEN : { <Ddot: "D." >}
TOKEN : { <Edot: "E." >}
TOKEN : { <Fdot: "F." >}


// Now some abbreviations
TOKEN : { <Abs: "Abs." >}
TOKEN : { <Abstr: "Abstr." >}
TOKEN : { <Add: "Add." >}
TOKEN : { <Approx: "Approx." >}
TOKEN : { <Apr: "Apr." >}
TOKEN : { <Atm: "Atm." >}
TOKEN : { <Aug: "Aug." >}
TOKEN : { <Bill: "Bill." >}
TOKEN : { <Bn: "Bn." >}
TOKEN : { <Bull: "Bull." >}
TOKEN : { <CF: "CF." >}
TOKEN : { <Ca: "Ca." >}
TOKEN : { <Calc: "Calc." >}
TOKEN : { <Capt: "Capt." >}
TOKEN : { <Cdn: "Cdn." >}
TOKEN : { <Cf: "Cf." >}
TOKEN : { <Ch: "Ch." >}
TOKEN : { <Chap: "Chap." >}
TOKEN : { <Coeff: "Coeff." >}
TOKEN : { <Col: "Col." >}
TOKEN : { <Com: "Com." >}
TOKEN : { <Conc: "Conc." >}
TOKEN : { <Cond: "Cond." >}
TOKEN : { <Corp: "Corp." >}
TOKEN : { <D: "D." >}
TOKEN : { <Dec: "Dec." >}
TOKEN : { <Deriv: "Deriv." >}
TOKEN : { <Dia: "Dia." >}
TOKEN : { <Diam: "Diam." >}
TOKEN : { <Din: "Din." >}
TOKEN : { <Dir: "Dir." >}
TOKEN : { <Div: "Div." >}
TOKEN : { <Docs: "Docs." >}
TOKEN : { <Dott: "Dott." >}
TOKEN : { <Dr: "Dr." >}
TOKEN : { <Esp: "Esp." >}
TOKEN : { <Est: "Est." >}
TOKEN : { <Esq: "Esq." >}
TOKEN : { <Exc: "Exc." >}
TOKEN : { <Excl: "Excl." >}
TOKEN : { <FIG: "FIG." >}
TOKEN : { <FIGS: "FIGS." >}
TOKEN : { <Feb: "Feb." >}
TOKEN : { <Fed: "Fed." >}
TOKEN : { <Fig: "Fig." >}
TOKEN : { <Fri: "Fri." >}
TOKEN : { <Govt: "Govt." >}
TOKEN : { <INT: "INT." >}
TOKEN : { <Inc: "Inc." >}
TOKEN : { <INC: "INC." >}
TOKEN : { <Incl: "Incl." >}
TOKEN : { <Ind: "Ind." >}
TOKEN : { <Ing: "Ing." >}
TOKEN : { <Jan: "Jan." >}
TOKEN : { <Jr: "Jr." >}
TOKEN : { <Jul: "Jul." >}
TOKEN : { <Jun: "Jun." >}
TOKEN : { <Ltd: "Ltd." >}
TOKEN : { <MM: "MM." >}
TOKEN : { <MR: "MR." >}
TOKEN : { <MRS: "MRS." >}
TOKEN : { <MS: "MS." >}
TOKEN : { <Mar: "Mar." >}
TOKEN : { <Max: "Max." >}
TOKEN : { <Messrs: "Messrs." >}
TOKEN : { <Mfg: "Mfg." >}
TOKEN : { <Mgr: "Mgr." >}
TOKEN : { <Mill: "Mill." >}
TOKEN : { <Misc: "Misc." >}
TOKEN : { <Mon: "Mon." >}
TOKEN : { <Mr: "Mr." >}
TOKEN : { <Mrs: "Mrs." >}
TOKEN : { <Ms: "Ms." >}
TOKEN : { <Mt: "Mt." >}
TOKEN : { <Nsmallo: "N\u00b0." >}
TOKEN : { <NO: "NO." >}
TOKEN : { <Neg: "Neg." >}
TOKEN : { <No: "No." >}
TOKEN : { <Nos: "Nos." >}
TOKEN : { <Nov: "Nov." >}
TOKEN : { <Obj: "Obj." >}
TOKEN : { <Oct: "Oct." >}
TOKEN : { <Par: "Par." >}
TOKEN : { <Para: "Para." >}
TOKEN : { <Phd: "Ph.D." >}
TOKEN : { <Pos: "Pos." >}
TOKEN : { <Pp: "Pp." >}
TOKEN : { <Prep: "Prep." >}
TOKEN : { <Prof: "Prof." >}
TOKEN : { <Pvt: "Pvt." >}
TOKEN : { <Rec: "Rec." >}
TOKEN : { <Ref: "Ref." >}
TOKEN : { <Reg: "Reg." >}
TOKEN : { <Res: "Res." >}
TOKEN : { <Resp: "Resp." >}
TOKEN : { <Rev: "Rev." >}
TOKEN : { <Sat: "Sat." >}
TOKEN : { <Sep: "Sep." >}
TOKEN : { <Sept: "Sept." >}
TOKEN : { <Sq: "Sq." >}
TOKEN : { <Sr: "Sr." >}
TOKEN : { <St: "St." >}
TOKEN : { <Sta: "Sta." >}
// Sun. seems to end sentences often - and (hopefully)
// is rarely used as an abbreviation within Sun docs <ooer>
//TOKEN : { <Sun: "Sun." >}
TOKEN : { <Suppl: "Suppl." >}
TOKEN : { <Tel: "Tel." >}
TOKEN : { <Tech: "Tech." >}
TOKEN : { <Temp: "Temp." >}
TOKEN : { <Thu: "Thu." >}
TOKEN : { <Thur: "Thur." >}
TOKEN : { <Thurs: "Thurs." >}
TOKEN : { <Tue: "Tue." >}
TOKEN : { <Tues: "Tues." >}
TOKEN : { <Univ: "Univ." >}
TOKEN : { <Util: "Util." >}
TOKEN : { <US: "U.S." >}
TOKEN : { <USA: "U.S.A.">}
TOKEN : { <Viz: "Viz." >}
TOKEN : { <Wed: "Wed." >}
TOKEN : { <abs: "abs." >}
TOKEN : { <abstr: "abstr." >}
TOKEN : { <app: "app." >}
TOKEN : { <appr: "appr." >}
TOKEN : { <approx: "approx." >}
TOKEN : { <apr: "apr." >}
TOKEN : { <atm: "atm." >}
TOKEN : { <aug: "aug." >}
TOKEN : { <bill: "bill." >}
TOKEN : { <bn: "bn." >}
TOKEN : { <bull: "bull." >}
TOKEN : { <ca: "ca." >}
TOKEN : { <calc: "calc." >}
TOKEN : { <capt: "capt." >}
TOKEN : { <cert: "cert." >}
TOKEN : { <cf: "cf." >}
TOKEN : { <chap: "chap." >}
TOKEN : { <circ: "circ." >}
TOKEN : { <coeff: "coeff." >}
TOKEN : { <col: "col." >}
TOKEN : { <com: "com." >}
TOKEN : { <conc: "conc." >}
TOKEN : { <cond: "cond." >}
TOKEN : { <dec: "dec." >}
TOKEN : { <deriv: "deriv." >}
TOKEN : { <dia: "dia." >}
TOKEN : { <diam: "diam." >}
TOKEN : { <din: "din." >}
TOKEN : { <dir: "dir." >}
TOKEN : { <docs: "docs." >}
TOKEN : { <dott: "dott." >}
TOKEN : { <dr: "dr." >}
TOKEN : { <eg: "e.g." >}
TOKEN : { <badeg: "eg." >}
TOKEN : { <esp: "esp." >}
TOKEN : { <est: "est." >}
TOKEN : { <estim: "estim." >}
TOKEN : { <etc: "etc." >}
TOKEN : { <exc: "exc." >}
TOKEN : { <excl: "excl." >}
TOKEN : { <feb: "feb." >}
TOKEN : { <fed: "fed." >}
TOKEN : { <fig: "fig." >}
TOKEN : { <fri: "fri." >}
TOKEN : { <govt: "govt." >}
TOKEN : { <ie: "i.e." >}
TOKEN : { <badie: "ie." >}
TOKEN : { <inc: "inc." >}
TOKEN : { <incl: "incl." >}
TOKEN : { <ind: "ind." >}
TOKEN : { <ing: "ing." >}
TOKEN : { <jan: "jan." >}
TOKEN : { <kg: "kg." >}
TOKEN : { <kh: "km./h.">}
TOKEN : { <kmph: "km.p.h.">}
TOKEN : { <lb: "lb." >}
TOKEN : { <mM: "mM." >}
TOKEN : { <mar: "mar." >}
TOKEN : { <max: "max." >}
TOKEN : { <messrs: "messrs." >}
TOKEN : { <mfg: "mfg." >}
TOKEN : { <mgr: "mgr." >}
TOKEN : { <mill: "mill." >}
TOKEN : { <misc: "misc." >}
TOKEN : { <mon: "mon." >}
TOKEN : { <mr: "mr." >}
TOKEN : { <mrs: "mrs." >}
TOKEN : { <ms: "ms." >}
TOKEN : { <mt: "mt." >}
TOKEN : { <mh: "m./h.">}
TOKEN : { <mph: "m.p.h.">}
TOKEN : { <neg: "neg." >}
TOKEN : { <no: "no." >}
TOKEN : { <nos: "nos." >}
TOKEN : { <nov: "nov." >}
TOKEN : { <oct: "oct." >}
TOKEN : { <oz: "oz." >}
TOKEN : { <pag: "pag." >}
TOKEN : { <par: "par." >}
TOKEN : { <para: "para." >}
TOKEN : { <pos: "pos." >}
TOKEN : { <pp: "pp." >}
TOKEN : { <prep: "prep." >}
TOKEN : { <prof: "prof." >}
TOKEN : { <rec: "rec." >}
TOKEN : { <ref: "ref." >}
TOKEN : { <reg: "reg." >}
TOKEN : { <res: "res." >}
TOKEN : { <resp: "resp." >}
TOKEN : { <rev: "rev." >}
TOKEN : { <sat: "sat." >}
TOKEN : { <sep: "sep." >}
TOKEN : { <sept: "sept." >}
TOKEN : { <sp: "sp." >}
TOKEN : { <spp: "spp." >}
TOKEN : { <sq: "sq." >}
TOKEN : { <st: "st." >}
TOKEN : { <sta: "sta." >}
// see comment for Sun
//TOKEN : { <sun: "sun." >}
TOKEN : { <suppl: "suppl." >}
TOKEN : { <tel: "tel." >}
TOKEN : { <tech: "tech." >}
TOKEN : { <temp: "temp." >}
TOKEN : { <thu: "thu." >}
TOKEN : { <thur: "thur." >}
TOKEN : { <thurs: "thurs." >}
TOKEN : { <tue: "tue." >}
TOKEN : { <tues: "tues." >}
TOKEN : { <univ: "univ." >}
TOKEN : { <util: "util." >}
TOKEN : { <viz: "viz." >}
TOKEN : { <vs: "vs." >}
TOKEN : { <wed: "wed." >}

// Swedish tokens 

TOKEN : { <Ang: "Ang." >}
TOKEN : { <Ank: "Ank." >}
TOKEN : { <Avd: "Avd." >}
TOKEN : { <Avg: "Avg." >}
TOKEN : { <Avs: "Avs." >}
TOKEN : { <Betr: "Betr." >}
TOKEN : { <Bil: "Bil." >}
TOKEN : { <Bitr: "Bitr." >}
TOKEN : { <Dvs: "Dvs." >}
TOKEN : { <Enl: "Enl." >}
TOKEN : { <Exp: "Exp." >}
TOKEN : { <Exv: "Exv." >}
TOKEN : { <Folj: "F\u00f6lj." >}
TOKEN : { <Fr: "Fr." >}
TOKEN : { <From: "Fr.o.m." >}
TOKEN : { <Foreg: "F\u00f6reg." >}
TOKEN : { <Gm: "Gm." >}
TOKEN : { <Hr: "Hr." >}
TOKEN : { <Kl: "Kl." >}
TOKEN : { <Mag: "Mag." >}
TOKEN : { <Tex: "T.ex." >}
TOKEN : { <ang: "ang." >}
TOKEN : { <ank: "ank." >}
TOKEN : { <avd: "avd." >}
TOKEN : { <avg: "avg." >}
TOKEN : { <avs: "avs." >}
TOKEN : { <betr: "betr." >}
TOKEN : { <bil: "bil." >}
TOKEN : { <bitr: "bitr." >}
TOKEN : { <dvs: "dvs." >}
TOKEN : { <enl: "enl." >}
TOKEN : { <exp: "exp." >}
TOKEN : { <exv: "exv." >}
TOKEN : { <folj: "f\u00f6lj." >}
TOKEN : { <fr: "fr." >}
TOKEN : { <from: "fr.o.m." >}
TOKEN : { <foreg: "f\u00f6reg." >}
TOKEN : { <gm: "gm." >}
TOKEN : { <hr: "hr." >}
TOKEN : { <kl: "kl." >}
TOKEN : { <mag: "mag." >}
TOKEN : { <tex: "t.ex." >}
TOKEN : { <Adr: "Adr." >}
TOKEN : { <adr: "adr." >}
TOKEN : { <Bla: "Bl.a." >}
TOKEN : { <bla: "bl.a." >}
TOKEN : { <Civek: "Civ.ek." >}
TOKEN : { <civek: "civ.ek." >}
TOKEN : { <Civing: "Civ.ing." >}
TOKEN : { <civing: "civ.ing." >}
TOKEN : { <Co: "Co." >}
TOKEN : { <div: "div." >}
TOKEN : { <Doc: "Doc." >}
TOKEN : { <doc: "doc." >}
TOKEN : { <Edyl: "E.dyl." >}
TOKEN : { <edyl: "e.dyl." >}
TOKEN : { <el: "el." >}
TOKEN : { <Ev: "Ev." >}
TOKEN : { <ev: "ev." >}
TOKEN : { <Ex: "Ex." >}
TOKEN : { <ex: "ex." >}
TOKEN : { <Exkl: "Exkl." >}
TOKEN : { <exkl: "exkl." >}
TOKEN : { <Fd: "F.d." >}
TOKEN : { <fd: "f.d." >}
TOKEN : { <ff: "ff." >}
TOKEN : { <Forts: "Forts." >}
TOKEN : { <forts: "forts." >}
TOKEN : { <Fo: "F.\u00f6." >}
TOKEN : { <fo: "f.\u00f6." >}
TOKEN : { <Ibl: "Ibl." >}
TOKEN : { <ibl: "ibl." >}
TOKEN : { <Inkl: "Inkl." >}
TOKEN : { <inkl: "inkl." >}
TOKEN : { <I: "I" >}
TOKEN : { <stf: "st.f." >}
TOKEN : { <i: "i" >}
TOKEN : { <Kr: "Kr." >}
TOKEN : { <kr: "kr." >}
TOKEN : { <lev: "lev." >}
TOKEN : { <Mfl: "M.fl." >}
TOKEN : { <mfl: "m.fl." >}
TOKEN : { <Min: "Min." >}
TOKEN : { <min: "min." >}
TOKEN : { <mm: "m.m." >}
TOKEN : { <Nuv: "Nuv." >}
TOKEN : { <nuv: "nuv." >}
TOKEN : { <Obs: "Obs." >}
TOKEN : { <obs: "obs." >}
TOKEN : { <od: "o.d." >}
TOKEN : { <odyl: "o.dyl." >}
TOKEN : { <Ordf: "Ordf." >}
TOKEN : { <ordf: "ordf." >}
TOKEN : { <osv: "osv." >}
TOKEN : { <Pg: "Pg." >}
TOKEN : { <pg: "pg." >}
TOKEN : { <pl: "pl." >}
TOKEN : { <plur: "plur." >}
TOKEN : { <PS: "P.S." >}
TOKEN : { <Sek: "Sek." >}
TOKEN : { <sek: "sek." >}
TOKEN : { <Sekr: "Sekr." >}
TOKEN : { <sekr: "sekr." >}
TOKEN : { <Sid: "Sid." >}
TOKEN : { <sid: "sid." >}
TOKEN : { <Sign: "Sign." >}
TOKEN : { <sign: "sign." >}
TOKEN : { <sk: "s.k." >}
TOKEN : { <Spec: "Spec." >}
TOKEN : { <spec: "spec." >}
TOKEN : { <tekn: "tekn." >}
TOKEN : { <Tf: "Tf." >}
TOKEN : { <tf: "tf." >}
TOKEN : { <Tim: "Tim." >}
TOKEN : { <tim: "tim." >}
// klemens suggested we add this
TOKEN : { <tdot: "t." >}
TOKEN : { <tr: "tr." >}
TOKEN : { <Tv: "T.v." >}
TOKEN : { <tv: "t.v." >}
TOKEN : { <Ung: "Ung." >}
TOKEN : { <ung: "ung." >}
TOKEN : { <Uppl: "Uppl." >}
TOKEN : { <uppl: "uppl." >}
TOKEN : { <v: "v." >}
TOKEN : { <Vol: "Vol." >}
TOKEN : { <vol: "vol." >}
TOKEN : { <Arg: "\u00c5rg." >}
TOKEN : { <arg: "\u00e5rg." >}
TOKEN : { <av: "\u00e4v." >}
TOKEN : { <o: "\u00f6." >}


// TOKEN : { <VERSIONNUMBER: ((["0"-"9"])+ "." (["0"-"9"]".")*)  > }

// hmm - deceptively similar... swedish number support
TOKEN : { <NUMBER: (["0"-"9"])+ (("."|",")(["0"-"9"])+)* ("."|",")? >}

// try and catch other abbreviations
TOKEN : 
{ 
    <ABBREV: ((~["\t"," ","\b","\f","\n","\r",".","!","?" ] ".")
	      (~["\t"," ","\b","\f","\n","\r",".","!","?" ] ".")+
	      (~["\t"," ","\b","\f","\n","\r",".","!","?" ])?) >
}
// Really this should be just "..." but people abuse the poor old elipsis.....
TOKEN : { <ELIPSIS: ("." (".")+)>  }

TOKEN : { <BRACKET: ["(","[","{",    ")","]","}"]>}

/*
Colons - who'd have thought there were this many !
02D0;MODIFIER LETTER TRIANGULAR COLON;Lm;0;L;;;;;N;;;;;
02D1;MODIFIER LETTER HALF TRIANGULAR COLON;Lm;0;L;;;;;N;;;;;
0703;SYRIAC SUPRALINEAR COLON;Po;0;AL;;;;;N;;;;;
0704;SYRIAC SUBLINEAR COLON;Po;0;AL;;;;;N;;;;;
0705;SYRIAC HORIZONTAL COLON;Po;0;AL;;;;;N;;;;;
0706;SYRIAC COLON SKEWED LEFT;Po;0;AL;;;;;N;;;;;
0707;SYRIAC COLON SKEWED RIGHT;Po;0;AL;;;;;N;;;;;
0708;SYRIAC SUPRALINEAR COLON SKEWED LEFT;Po;0;AL;;;;;N;;;;;
0709;SYRIAC SUBLINEAR COLON SKEWED RIGHT;Po;0;AL;;;;;N;;;;;
1365;ETHIOPIC COLON;Po;0;L;;;;;N;;;;;
1366;ETHIOPIC PREFACE COLON;Po;0;L;;;;;N;;;;;
1362;ETHIOPIC FULL STOP;Po;0;L;;;;;N;;;;;
1804;MONGOLIAN COLON;Po;0;ON;;;;;N;;;;;
20A1;COLON SIGN;Sc;0;ET;;;;;N;;;;;
FF1A;FULLWIDTH COLON;Po;0;CS;<wide> 003A;;;;N;;;;;


0589;ARMENIAN FULL STOP;Po;0;L;;;;;N;ARMENIAN PERIOD;;;;
06D4;ARABIC FULL STOP;Po;0;AL;;;;;N;ARABIC PERIOD;;;;
3002;IDEOGRAPHIC FULL STOP;Po;0;ON;;;;;N;IDEOGRAPHIC PERIOD;;;;
30FB;KATAKANA MIDDLE DOT;Pc;0;ON;;;;;N;;;;;
FF01;FULLWIDTH EXCLAMATION MARK;Po;0;ON;<wide> 0021;;;;N;;;;;
FF0E;FULLWIDTH FULL STOP;Po;0;CS;<wide> 002E;;;;N;FULLWIDTH PERIOD;;;;
FF0F;FULLWIDTH SOLIDUS;Po;0;ES;<wide> 002F;;;;N;FULLWIDTH SLASH;;;;
FF1F;FULLWIDTH QUESTION MARK;Po;0;ON;<wide> 003F;;;;N;;;;;
FF61;HALFWIDTH IDEOGRAPHIC FULL STOP;Po;0;ON;<narrow> 3002;;;;N;HALFWIDTH IDEOGRAPHIC PERIOD;;;;
FE52;SMALL FULL STOP;Po;0;CS;<small> 002E;;;;N;SMALL PERIOD;;;;
FE54;SMALL SEMICOLON;Po;0;ON;<small> 003B;;;;N;;;;;
FE55;SMALL COLON;Po;0;CS;<small> 003A;;;;N;;;;;
FE56;SMALL QUESTION MARK;Po;0;ON;<small> 003F;;;;N;;;;;
FE57;SMALL EXCLAMATION MARK;Po;0;ON;<small> 0021;;;;N;;;;;

// more full stops
06EA;ARABIC EMPTY CENTRE LOW STOP;Mn;220;NSM;;;;;N;;;;;
06EB;ARABIC EMPTY CENTRE HIGH STOP;Mn;230;NSM;;;;;N;;;;;
06EC;ARABIC ROUNDED HIGH STOP WITH FILLED CENTRE;Mn;230;NSM;;;;;N;;;;;
0701;SYRIAC SUPRALINEAR FULL STOP;Po;0;AL;;;;;N;;;;;
0702;SYRIAC SUBLINEAR FULL STOP;Po;0;AL;;;;;N;;;;;
1362;ETHIOPIC FULL STOP;Po;0;L;;;;;N;;;;;
1803;MONGOLIAN FULL STOP;Po;0;ON;;;;;N;;;;;
1809;MONGOLIAN MANCHU FULL STOP;Po;0;ON;;;;;N;;;;;


*/

TOKEN :
{
    <SENTSEP: ([".","!","?",":",
	       "\u02d0","\u02d1","\u0703","\u0704","\u0705","\u0706","\u0707",
	       "\u0708","\u0709","\u1365","\u1366","\u1362","\u1804","\u20a1",
	       "\uff1a",

		"\u0589","\u06d4","\u3002","\u30fb","\uff01","\uff0e","\uff0f",
	       "\uff1f","\uff61","\ufe52","\ufe54","\ufe55","\ufe56","\ufe57",
	       
	       "\u06ea","\u06eb","\u06ec","\u0701","\u0702",
	       "\u1362","\u1803","\u1809"

    ]) >
}

// add to allow things like "600-lb. gorilla"
TOKEN : { <DASH: "-">}

// deals with filenames, shared object names and manpage names
TOKEN : { <LETTERDOTNUMBER: (["a"-"z"] | ["A"-"Z"] | "/")*"."(["0"-"9"])+ ("."(["0"-"9"])+)* >}

// a word (well, a string of characters really)
/* the QUOTE token originally had the ' character - but now, we're treating
   it like whitespace, to deal with the SunTrans1 idea that the text "it's" should
   be treated as two words - so the word token needs to exclude ' as a valid word
   
   I'm also allowing '-' in a word
   */
TOKEN : 
{
    <WORD: (~[ ",","'","\t"," ","\b","\f","\n","\r",".","&","!","?","0"-"9","\"","(","[","{",")","]","}","<",

	     "-",":","\u02d0","\u02d1","\u0703","\u0704","\u0705","\u0706","\u0707",
	     "\u0708","\u0709","\u1365","\u1366","\u1362","\u1804","\u20a1",
	     "\uff1a",

	     "\u0589","\u06d4","\u3002","\u30fb","\uff01","\uff0e","\uff0f",
	     "\uff1f","\uff61","\ufe52","\ufe54","\ufe55","\ufe56","\ufe57",

             "\u06ea","\u06eb","\u06ec","\u0701","\u0702",
	     "\u1362","\u1803","\u1809"

 ])+   
 >
}

TOKEN :
/* for non separating punctuation that shouldn't be counted as a word 
   - just a comma for now */
{  <NONSEPPUNCT: (",")> }


/*
 *  Productions
 */

void file():
{;}
{
    (formatting())? ((formatting())? segment())* (formatting())? (<EOF>)?
}

void segment():
{
    String s="";
    String st="";
    Token t;
}
{
    ( (//(ignorednewline())?
       (t=<QUOTE> {s+=t.image;})?
        (t=<BRACKET> {s+=t.image;})?
        (
	 (st=sentence() {s+=st;} | bracketedsentence() {s+=st;}) (st=sentsep() {s+=st;})?
 	)
        (t=<BRACKET> {s+=t.image;})?
       (t=<QUOTE> {s+=t.image;})?
       )  
      |
      st=sentsep() {s+=st;} 
      )
	
	
	{jjtThis.setNodeData(s);}
}

String sentsep():
{
  String s = "";
  Token t;
}
{
    ( (t=<ELIPSIS> { s+=t.image;}) | 
      (t=<SENTSEP> {s+=t.image;})
    )
	{jjtThis.setNodeData(s); 
	return s;}
}


String sentence():
{
  Token t;
  String s = "";
  String st = "";
}
{
   (t=<numberdot> {s=t.image; System.out.println ("see number dot token");})?

   (
    (
     st=tag() {s+=st;} |     
     st=dashedline() {s+=st;} |
     st=dashedword() {s+=st;} |
     st=numabbrev() {s+=st;} |
     st=number() {s+=st;} |
     st=word() {s+=st;} |
     t=<NONSEPPUNCT> {s+=t.image;} |
     t=<BRACKET> {s+=t.image;} |    
     ignorednewline() {s+=" ";} |

     st=whitespace() {s+=st;}
    )
   )+  { jjtThis.setNodeData(s);
         return s;}
}

// this is for things like "600-lb. gorilla"
String numabbrev():
{
    String s="";
    String st="";
    Token t;
}
{
    (t=<NUMBER> {s=t.image;} t=<DASH> {s+=t.image;} st=abbrev()  {s+=st;}) {return s;}
}

// gets counted as a single word
String dashedword():
{
 String s = "";
 Token t;
}
{
     
     ( (t=<WORD> {s=t.image;} | t=<NUMBER> {s=t.image;})
       (t=<DASH> {s+=t.image;}) 
       (t=<WORD>  { s+=t.image;} | t=<NUMBER> {s+=t.image;})
      )+ 
    
   { jjtThis.setNodeData(s); return s;}

}

// doesn't get word counted
String number():
{
 String s = "";
 String st = "";
 Token t;
}
{     
      (t=<NUMBER> { s=t.image;}) {jjtThis.setNodeData(s);return s;}
}


// gets counted as a single word
String word():
{
 String s = "";
 String st = "";
 Token t;
}
{
    ( 
     (st=numabbrev() {s=st;}) |
     (st=time() {s=st;}) |
     (st=abbrev() {s=st;}) |
     (t=<QUOTEDWORD> {s=t.image;}) | 
     (t=<QUOTE> {s=t.image;}) |
     (st=filename() {s=st;}) |
     (st=email() {s=st;}) |
     (st=url() {s=st;}) |
     (t=<DASH> {s=t.image;}) |
     (t=<WORD>  { s=t.image;}) |
     (st=entity() {s+=st;})|
     (st=amp() {s+=st;})
    )
   { jjtThis.setNodeData(s); return s;}

}


// doesn't get counted
String dashedline():
{
 String s = "";
 Token t;
}
{
     
     t=<DASH> {s+=t.image;} (t=<DASH> {s+=t.image;})+
      
    
   { jjtThis.setNodeData(s); return s;}

}

String bracketedsentence():
{
 String s = "";
 String st = "";
 Token t;
}
{
    ( (t=<BRACKET> {s+=t.image;})
      (

       st=dashedword() {s+=st;} |
       st=tag() {s+=st;} |
       st=number() {s+=st;} |
       st=word() {s+=st;} |
       t=<NONSEPPUNCT> {s+=t.image;} |
       ignorednewline() {s+=" ";} |
       st=whitespace() {s+=st;}
       
      )+
      (t=<BRACKET> {s+=t.image;})

    )
   { jjtThis.setNodeData(s); return s;}

}


String filename():
{
    Token t;
    String s="";
}{
        (t=<WORD> {s+=t.image;})? t=<EXTENSION> {s+=t.image;}
	{return s;}
}


String email():
{
    Token t;
    String s="";
    String st="";
}{
    
    (t=<EMAIL> {st=t.image; s+=st;})
    
     {return s;}
}

String url():
{
    Token t;
    String s="";
    String st="";
}{
    (t=<URL> {st=t.image; s+=st;})
     {return s;}
}

String time():
{
    Token t;
    String s="";
}
{   (t=<TIME> {s+=t.image;}) {return s;}
}


// This production is being used for lots of things now that look like productions
String abbrev():
{
    String s="";
    Token t;
}
{   
    (
     // general stuff
     (t=<ABBREV> {s=t.image;})|
     (t=<LETTERDOTNUMBER> {s=t.image;}) |
     (t=<NETDOMAIN> {s=t.image;}) |
     // terms - sorry...
     (t=<JumpStart> {s=t.image;}) |
     (t=<crapsoftware> {s=t.image;}) |
     (t=<Yahoo> {s=t.image;}) |
     (t=<sundotcom> {s=t.image;}) |
     (t=<sunnet> {s=t.image;}) |
     ///(t=<javaclass> {s=t.image;}) |
     // common doc mistakes - sentsep within brackets.
     // Can't use these since when I put them in, sentence like :

     // (Can the segmenter handle parens ?)

     // don't get seen as a segment. This is mutually exclusive with :

     // Note: Handles the bad punctuation '(Not Sun Blue.)' correctly.

     //(t=<dotbracket> {s=t.image;}) |
     //(t=<exclambracket> {s=t.image;}) |
     //(t=<questionbracket> {s=t.image;}) |
     
     (t=<quoteelipsis> {s=t.image;}) |
  
     // bulleted lists ? (yes, I'm only going to "f")
     (t=<adot> {s=t.image;}) |
     (t=<bdot> {s=t.image;}) |
     (t=<cdot> {s=t.image;}) |
     (t=<ddot> {s=t.image;}) |
     (t=<edot> {s=t.image;}) |
     (t=<fdot> {s=t.image;}) |

     (t=<Adot> {s=t.image;}) |
     (t=<Bdot> {s=t.image;}) |
     (t=<Cdot> {s=t.image;}) |
     // D. is already an abbrev below
     //(t=<Ddot> {s=t.image;}) |
     (t=<Edot> {s=t.image;}) |
     (t=<Fdot> {s=t.image;}) |

    
     // real abbreviations
     (t=<Abs> {s=t.image;}) |
     (t=<Abstr> {s=t.image;}) |
     (t=<Add> {s=t.image;}) |
     (t=<Approx> {s=t.image;}) |
     (t=<Apr> {s=t.image;}) |
     (t=<Atm> {s=t.image;}) |
     (t=<Aug> {s=t.image;}) |
     (t=<Bill> {s=t.image;}) |
     (t=<Bn> {s=t.image;}) |
     (t=<Bull> {s=t.image;}) |
     (t=<CF> {s=t.image;}) |
     (t=<Ca> {s=t.image;}) |
     (t=<Calc> {s=t.image;}) |
     (t=<Capt> {s=t.image;}) |
     (t=<Cdn> {s=t.image;}) |
     (t=<Cf> {s=t.image;}) |
     (t=<Ch> {s=t.image;}) |
     (t=<Chap> {s=t.image;}) |
     (t=<Coeff> {s=t.image;}) |
     (t=<Col> {s=t.image;}) |
     (t=<Com> {s=t.image;}) |
     (t=<Conc> {s=t.image;}) |
     (t=<Cond> {s=t.image;}) |
     (t=<Corp> {s=t.image;}) |
     (t=<D> {s=t.image;}) |
     (t=<Dec> {s=t.image;}) |
     (t=<Deriv> {s=t.image;}) |
     (t=<Dia> {s=t.image;}) |
     (t=<Diam> {s=t.image;}) |
     (t=<Din> {s=t.image;}) |
     (t=<Dir> {s=t.image;}) |
     (t=<Div> {s=t.image;}) |
     (t=<Docs> {s=t.image;}) |
     (t=<Dott> {s=t.image;}) |
     (t=<Dr> {s=t.image;}) |
     (t=<Esp> {s=t.image;}) |
     (t=<Est> {s=t.image;}) |
     (t=<Esq> {s=t.image;}) |
     (t=<Exc> {s=t.image;}) |
     (t=<Excl> {s=t.image;}) |
     (t=<FIG> {s=t.image;}) |
     (t=<FIGS> {s=t.image;}) |
     (t=<Feb> {s=t.image;}) |
     (t=<Fed> {s=t.image;}) |
     (t=<Fig> {s=t.image;}) |
     (t=<Fri> {s=t.image;}) |
     (t=<Govt> {s=t.image;}) |
     (t=<INT> {s=t.image;}) |
     (t=<Inc> {s=t.image;}) |
     (t=<INC> {s=t.image;}) |
     (t=<Incl> {s=t.image;}) |
     (t=<Ind> {s=t.image;}) |
     (t=<Ing> {s=t.image;}) |
     (t=<Jan> {s=t.image;}) |
     (t=<Jr> {s=t.image;}) |
     (t=<Jul> {s=t.image;}) |
     (t=<Jun> {s=t.image;}) |
     (t=<Ltd> {s=t.image;})| 
     (t=<MM> {s=t.image;}) |
     (t=<MR> {s=t.image;}) |
     (t=<MRS> {s=t.image;}) |
     (t=<MS> {s=t.image;}) |
     (t=<Mar> {s=t.image;}) |
     (t=<Max> {s=t.image;}) |
     (t=<Messrs> {s=t.image;}) |
     (t=<Mfg> {s=t.image;}) |
     (t=<Mgr> {s=t.image;}) |
     (t=<Mill> {s=t.image;}) |
     (t=<Misc> {s=t.image;}) |
     (t=<Mon> {s=t.image;}) |
     (t=<Mr> {s=t.image;}) |
     (t=<Mrs> {s=t.image;}) |
     (t=<Ms> {s=t.image;}) |
     (t=<Mt> {s=t.image;}) |
     (t=<Nsmallo> {s=t.image;}) |
     (t=<NO> {s=t.image;}) |
     (t=<Neg> {s=t.image;}) |
     (t=<No> {s=t.image;}) |
     (t=<Nos> {s=t.image;}) |
     (t=<Nov> {s=t.image;}) |
     (t=<Obj> {s=t.image;}) |
     (t=<Oct> {s=t.image;}) |
     (t=<Par> {s=t.image;}) |
     (t=<Para> {s=t.image;}) |
     (t=<Phd> {s=t.image;}) |
     (t=<Pos> {s=t.image;}) |
     (t=<Pp> {s=t.image;}) |
     (t=<Prep> {s=t.image;}) |
     (t=<Prof> {s=t.image;}) |
     (t=<Pvt> {s=t.image;}) |
     (t=<Rec> {s=t.image;}) |
     (t=<Ref> {s=t.image;}) |
     (t=<Reg> {s=t.image;}) |
     (t=<Res> {s=t.image;}) |
     (t=<Resp> {s=t.image;}) |
     (t=<Rev> {s=t.image;}) |
     (t=<Sat> {s=t.image;}) |
     (t=<Sep> {s=t.image;}) |
     (t=<Sept> {s=t.image;}) |
     (t=<Sq> {s=t.image;}) |
     (t=<Sr> {s=t.image;}) |
     (t=<St> {s=t.image;}) |
     (t=<Sta> {s=t.image;}) |
     // Hacking out the name of our esteemed company
     // I wonder could we re-spell "Sunday" to "Sughnday"
     // to avoid this confusion ?
     //     (t=<Sun> {s=t.image;}) |
     (t=<Suppl> {s=t.image;}) |
     (t=<Tel> {s=t.image;}) |
     (t=<Tech> {s=t.image;}) |
     (t=<Temp> {s=t.image;}) |
     (t=<Thu> {s=t.image;}) |
     (t=<Thur> {s=t.image;}) |
     (t=<Thurs> {s=t.image;}) |
     (t=<Tue> {s=t.image;}) |
     (t=<Tues> {s=t.image;}) |
     (t=<Univ> {s=t.image;}) |
     (t=<Util> {s=t.image;}) |
     (t=<US> {s=t.image;}) |
     (t=<USA> {s=t.image;}) |
     (t=<Viz> {s=t.image;}) |
     (t=<Wed> {s=t.image;}) |
     (t=<abs> {s=t.image;}) |
     (t=<abstr> {s=t.image;}) |
     (t=<app> {s=t.image;}) |
     (t=<appr> {s=t.image;}) |
     (t=<approx> {s=t.image;}) |
     (t=<apr> {s=t.image;}) |
     (t=<atm> {s=t.image;}) |
     (t=<aug> {s=t.image;}) |
     (t=<bill> {s=t.image;}) |
     (t=<bn> {s=t.image;}) |
     (t=<bull> {s=t.image;}) |
     (t=<ca> {s=t.image;}) |
     (t=<calc> {s=t.image;}) |
     (t=<capt> {s=t.image;}) |
     (t=<cert> {s=t.image;}) |
     (t=<cf> {s=t.image;}) |
     (t=<chap> {s=t.image;}) |
     (t=<circ> {s=t.image;}) |
     (t=<coeff> {s=t.image;}) |
     (t=<col> {s=t.image;}) |
     (t=<com> {s=t.image;}) |
     (t=<conc> {s=t.image;}) |
     (t=<cond> {s=t.image;}) |
     (t=<dec> {s=t.image;}) |
     (t=<deriv> {s=t.image;}) |
     (t=<dia> {s=t.image;}) |
     (t=<diam> {s=t.image;}) |
     (t=<din> {s=t.image;}) |
     (t=<dir> {s=t.image;}) |
     (t=<docs> {s=t.image;}) |
     (t=<dott> {s=t.image;}) |
     (t=<dr> {s=t.image;}) |
     (t=<eg> {s=t.image;}) |
     (t=<badeg> {s=t.image;}) |
     (t=<esp> {s=t.image;}) |
     (t=<est> {s=t.image;}) |
     (t=<estim> {s=t.image;}) |
     (t=<etc> {s=t.image;}) |
     (t=<exc> {s=t.image;}) |
     (t=<excl> {s=t.image;}) |
     (t=<feb> {s=t.image;}) |
     (t=<fed> {s=t.image;}) |
     (t=<fig> {s=t.image;}) |
     (t=<fri> {s=t.image;}) |
     (t=<govt> {s=t.image;}) |
     (t=<ie> {s=t.image;}) |
     (t=<badie> {s=t.image;}) |
     (t=<inc> {s=t.image;}) |
     (t=<incl> {s=t.image;}) |
     (t=<ind> {s=t.image;}) |
     (t=<ing> {s=t.image;}) |
     (t=<jan> {s=t.image;}) |
     (t=<kg> {s=t.image;}) |
     (t=<kh> {s=t.image;}) |
     (t=<kmph> {s=t.image;}) |
     (t=<lb> {s=t.image;}) |
     (t=<mh> {s=t.image;}) |
     (t=<mph> {s=t.image;}) |
     (t=<mM> {s=t.image;}) |
     (t=<mar> {s=t.image;}) |
     (t=<max> {s=t.image;}) |
     (t=<messrs> {s=t.image;}) |
     (t=<mfg> {s=t.image;}) |
     (t=<mgr> {s=t.image;}) |
     (t=<mill> {s=t.image;}) |
     (t=<misc> {s=t.image;}) |
     (t=<mon> {s=t.image;}) |
     (t=<mr> {s=t.image;}) |
     (t=<mrs> {s=t.image;}) |
     (t=<ms> {s=t.image;}) |
     (t=<mt> {s=t.image;}) |
     (t=<neg> {s=t.image;}) |
     (t=<no> {s=t.image;}) |
     (t=<nos> {s=t.image;}) |
     (t=<nov> {s=t.image;}) |
     (t=<oct> {s=t.image;}) |
     (t=<oz> {s=t.image;}) |
   
     (t=<pag> {s=t.image;}) |
     (t=<par> {s=t.image;}) |
     (t=<para> {s=t.image;}) |
     (t=<pos> {s=t.image;}) |
     (t=<pp> {s=t.image;}) |
     (t=<prep> {s=t.image;}) |
     (t=<prof> {s=t.image;}) |
     (t=<rec> {s=t.image;}) |
     (t=<ref> {s=t.image;}) |
     (t=<reg> {s=t.image;}) |
     (t=<res> {s=t.image;}) |
     (t=<resp> {s=t.image;}) |
     (t=<rev> {s=t.image;}) |
     (t=<sat> {s=t.image;}) |
     (t=<sep> {s=t.image;}) |
     (t=<sept> {s=t.image;}) |
     (t=<sp> {s=t.image;}) |
     (t=<spp> {s=t.image;}) |
     (t=<sq> {s=t.image;}) |
     (t=<st> {s=t.image;}) |
     (t=<sta> {s=t.image;}) |
     // removing this !
     //(t=<sun> {s=t.image;}) |
     (t=<suppl> {s=t.image;}) |
     (t=<tel> {s=t.image;}) |
     (t=<tech> {s=t.image;}) |
     (t=<temp> {s=t.image;}) |
     (t=<thu> {s=t.image;}) |
     (t=<thur> {s=t.image;}) |
     (t=<thurs> {s=t.image;}) |
     (t=<tue> {s=t.image;}) |
     (t=<tues> {s=t.image;}) |
     (t=<univ> {s=t.image;}) |
     (t=<util> {s=t.image;}) |
     (t=<viz> {s=t.image;}) |
     (t=<vs> {s=t.image;}) |
     (t=<wed> {s=t.image;}) |

// Swedish tokens

(t=<Ang> {s=t.image;}) |
(t=<Ank> {s=t.image;}) |
(t=<Avd> {s=t.image;}) |
(t=<Avg> {s=t.image;}) |
(t=<Avs> {s=t.image;}) |
(t=<Betr> {s=t.image;}) |
(t=<Bil> {s=t.image;}) |
(t=<Bitr> {s=t.image;}) |
(t=<Dvs> {s=t.image;}) |
(t=<Enl> {s=t.image;}) |
(t=<Exp> {s=t.image;}) |
(t=<Exv> {s=t.image;}) |
(t=<Folj> {s=t.image;}) |
(t=<Fr> {s=t.image;}) |
(t=<From> {s=t.image;}) |
(t=<Foreg> {s=t.image;}) |
(t=<Gm> {s=t.image;}) |
(t=<Hr> {s=t.image;}) |
(t=<Kl> {s=t.image;}) |
(t=<Mag> {s=t.image;}) |
(t=<Tex> {s=t.image;}) |
(t=<ang> {s=t.image;}) |
(t=<ank> {s=t.image;}) |
(t=<avd> {s=t.image;}) |
(t=<avg> {s=t.image;}) |
(t=<avs> {s=t.image;}) |
(t=<betr> {s=t.image;}) |
(t=<bil> {s=t.image;}) |
(t=<bitr> {s=t.image;}) |
(t=<dvs> {s=t.image;}) |
(t=<enl> {s=t.image;}) |
(t=<exp> {s=t.image;}) |
(t=<exv> {s=t.image;}) |
(t=<folj> {s=t.image;}) |
(t=<fr> {s=t.image;}) |
(t=<from> {s=t.image;}) |
(t=<foreg> {s=t.image;}) |
(t=<gm> {s=t.image;}) |
(t=<hr> {s=t.image;}) |
(t=<kl> {s=t.image;}) |
(t=<mag> {s=t.image;}) |
(t=<tex> {s=t.image;}) |
(t=<Adr> {s=t.image;}) |
(t=<adr> {s=t.image;}) |
(t=<Bla> {s=t.image;}) |
(t=<bla> {s=t.image;}) |
(t=<Civek> {s=t.image;}) |
(t=<civek> {s=t.image;}) |
(t=<Civing> {s=t.image;}) |
(t=<civing> {s=t.image;}) |
(t=<Co> {s=t.image;}) |
(t=<div> {s=t.image;}) |
(t=<Doc> {s=t.image;}) |
(t=<doc> {s=t.image;}) |
(t=<Edyl> {s=t.image;}) |
(t=<edyl> {s=t.image;}) |
(t=<el> {s=t.image;}) |
(t=<Ev> {s=t.image;}) |
(t=<ev> {s=t.image;}) |
(t=<Ex> {s=t.image;}) |
(t=<ex> {s=t.image;}) |
(t=<Exkl> {s=t.image;}) |
(t=<exkl> {s=t.image;}) |
(t=<Fd> {s=t.image;}) |
(t=<fd> {s=t.image;}) |
(t=<ff> {s=t.image;}) |
(t=<Forts> {s=t.image;}) |
(t=<forts> {s=t.image;}) |
(t=<Fo> {s=t.image;}) |
(t=<fo> {s=t.image;}) |
(t=<Ibl> {s=t.image;}) |
(t=<ibl> {s=t.image;}) |
(t=<Inkl> {s=t.image;}) |
(t=<inkl> {s=t.image;}) |
(t=<I> {s=t.image;}) |
(t=<stf> {s=t.image;}) |
(t=<i> {s=t.image;}) |
(t=<stf> {s=t.image;}) |
(t=<Kr> {s=t.image;}) |
(t=<kr> {s=t.image;}) |
(t=<lev> {s=t.image;}) |
(t=<Mfl> {s=t.image;}) |
(t=<mfl> {s=t.image;}) |
(t=<Min> {s=t.image;}) |
(t=<min> {s=t.image;}) |
(t=<mm> {s=t.image;}) |
(t=<Nuv> {s=t.image;}) |
(t=<nuv> {s=t.image;}) |
(t=<Obs> {s=t.image;}) |
(t=<obs> {s=t.image;}) |
(t=<od> {s=t.image;}) |
(t=<odyl> {s=t.image;}) |
(t=<Ordf> {s=t.image;}) |
(t=<ordf> {s=t.image;}) |
(t=<osv> {s=t.image;}) |
(t=<Pg> {s=t.image;}) |
(t=<pg> {s=t.image;}) |
(t=<pl> {s=t.image;}) |
(t=<plur> {s=t.image;}) |
(t=<PS> {s=t.image;}) |
(t=<Sek> {s=t.image;}) |
(t=<sek> {s=t.image;}) |
(t=<Sekr> {s=t.image;}) |
(t=<sekr> {s=t.image;}) |
(t=<Sid> {s=t.image;}) |
(t=<sid> {s=t.image;}) |
(t=<Sign> {s=t.image;}) |
(t=<sign> {s=t.image;}) |
(t=<sk> {s=t.image;}) |
(t=<Spec> {s=t.image;}) |
(t=<spec> {s=t.image;}) |
(t=<tekn> {s=t.image;}) |
(t=<tdot> {s=t.image;}) |
(t=<Tf> {s=t.image;}) |
(t=<tf> {s=t.image;}) |
(t=<Tim> {s=t.image;}) |
(t=<tim> {s=t.image;}) |
(t=<tr> {s=t.image;}) |
(t=<Tv> {s=t.image;}) |
(t=<tv> {s=t.image;}) |
(t=<Ung> {s=t.image;}) |
(t=<ung> {s=t.image;}) |
(t=<Uppl> {s=t.image;}) |
(t=<uppl> {s=t.image;}) |
(t=<v> {s=t.image;}) |
(t=<Vol> {s=t.image;}) |
(t=<vol> {s=t.image;}) |
(t=<Arg> {s=t.image;}) |
(t=<arg> {s=t.image;}) |
(t=<av> {s=t.image;}) |
(t=<o> {s=t.image;}) |


     (t=<backslashdot> {s=t.image;}) |
     (t=<dotbackslash> {s=t.image;}) |
     (t=<dotslash> {s=t.image;}) |
     (t=<slashdot> {s=t.image;})) { jjtThis.setNodeData(s); return s;}
}


String whitespace():
{
 String s = "";
 Token t;
}
{
  (t=<WS> { s+=t.image;})+ { jjtThis.setNodeData(s);return s;}

}


String formatting():
{
    String s="";
    Token t;
}
{ 
    (
     (t=<FORMATTING> { s+=t.image;}) | 
     (t=<WS> {s+=t.image;}))+ { jjtThis.setNodeData(s);return s;}  
 
}
 
String ignorednewline():
{
    String s="";
    Token t;
}
{ 
    ((t=<SLASHNSPACE> {s+=" ";}) |
     (t=<FORMATTING> { s+=t.image;})+){ jjtThis.setNodeData(s);return s;}  
 
} 

String tag() :
{String s="";}
{
  (s=open_tag() | s=close_tag()) {return s;}
}

String open_tag() :
{
  Token t;
  String s = "";
}
{
  (
    t=<STAGO> { s += t.image; }
    (t=<WS> {s+=t.image;})?
    t=<TAGNAME>	 { s += t.image;  }
    (t=<WS> {s+=t.image;})?

    ( t=<ATTRIBS>  { s += t.image;  }
	 (t=<WS> {s +=t.image; })?
    )*

    t=<TAGC> { s += t.image; }
  )
  {  jjtThis.setNodeData(s); return s;}
}

String close_tag() :
{
  Token t;
  String s = "";
}
{
  (
    t=<ETAGO> { s += t.image; }
    (t=<WS> {s+=t.image;})?
    ( t=<TAGNAME>  { s += t.image;
                      }
	(t=<WS> {s+=t.image;})?
    )?	/* '?' included to cover possible tag minimization */
    t=<TAGC> { s += t.image; }
  )
  {  jjtThis.setNodeData(s); return s; }
}

String entity():
{
    String s="";
    Token t;
}
{ // Html/Sgml/Xml workarounds
    (t=<entity> {s=t.image;}) {jjtThis.setNodeData(s);return s;}
}


String amp():
{
    String s="";
    Token t;
}
{ // Html/Sgml/Xml workarounds
    (t=<AMP> {s=t.image;}) {jjtThis.setNodeData(s);return s;}
}

